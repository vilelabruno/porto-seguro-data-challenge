{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "from geopy.distance import geodesic "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "target_train = df_train['y'].values\n",
    "id_test = df_test['id'].values\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_train[\"var7\"], _ = pd.factorize(pd.cut(df_train[\"var7\"], 4))\n",
    "df_test[\"var7\"], _ =  pd.factorize(pd.cut(df_test[\"var7\"], 4))\n",
    "df_train[\"var9\"], _ = pd.factorize(pd.cut(df_train[\"var9\"], 4))\n",
    "df_test[\"var9\"], _ =  pd.factorize(pd.cut(df_test[\"var9\"], 4))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dummies = 20\n",
    "\n",
    "for col in df_test.columns: # 100\n",
    "    if (len(df_test[col].unique()) < dummies) and (len(df_test[col].unique()) == len(df_train[col].unique())):\n",
    "        df_train = pd.get_dummies(df_train, columns=[col])\n",
    "        df_test = pd.get_dummies(df_test, columns=[col])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train = np.array(df_train.drop(['y','id'], axis = 1))\n",
    "test = np.array(df_test.drop(['id'], axis = 1))\n",
    "\n",
    "xgb_preds = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 3228, shuffle = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "def xgb_f1(y, t, threshold=0.5):\n",
    "    t = t.get_label()\n",
    "    y_bin = (y > threshold).astype(int) # works for both type(y) == <class 'numpy.ndarray'> and type(y) == <class 'pandas.core.series.Series'>\n",
    "    return 'f1',f1_score(t,y_bin)\n",
    "err = 0\n",
    "err2 = 0\n",
    "err3 = 0\n",
    "err4 = 0\n",
    "err5 = 0\n",
    "errLL = 0\n",
    "cutPoint = 0.36\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train_X, valid_X = train[train_index], train[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "    #xgb_params = {'eta': 0.11, 'max_depth': 5, 'subsample': 0.4, 'colsample_bytree': 0.4, 'objective': 'binary:logistic', 'min_child_weight': 15, 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, maximize=True, verbose_eval=50, early_stopping_rounds=100)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    pG = model.predict(d_valid)\n",
    "\n",
    "    errLL += log_loss(valid_y, pG)\n",
    "    p = pG\n",
    "    p[p > cutPoint] = 1\n",
    "    p[p != 1] = 0\n",
    "    err += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err2 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err3 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err4 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err5 += f1_score(valid_y, p)\n",
    "    print(err)\n",
    "    print(model.get_score(importance_type='gain'))\n",
    "    xgb_preds.append(list(xgb_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:31:41] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82521\tvalid-auc:0.80470\n",
      "[50]\ttrain-auc:0.88170\tvalid-auc:0.85571\n",
      "[100]\ttrain-auc:0.88689\tvalid-auc:0.86199\n",
      "[150]\ttrain-auc:0.89592\tvalid-auc:0.87034\n",
      "[200]\ttrain-auc:0.90638\tvalid-auc:0.87639\n",
      "[250]\ttrain-auc:0.91473\tvalid-auc:0.88087\n",
      "[300]\ttrain-auc:0.92187\tvalid-auc:0.88308\n",
      "[350]\ttrain-auc:0.92762\tvalid-auc:0.88521\n",
      "[400]\ttrain-auc:0.93322\tvalid-auc:0.88621\n",
      "[450]\ttrain-auc:0.93788\tvalid-auc:0.88727\n",
      "[500]\ttrain-auc:0.94181\tvalid-auc:0.88828\n",
      "[550]\ttrain-auc:0.94557\tvalid-auc:0.88893\n",
      "[600]\ttrain-auc:0.94920\tvalid-auc:0.88937\n",
      "[650]\ttrain-auc:0.95228\tvalid-auc:0.88990\n",
      "[700]\ttrain-auc:0.95512\tvalid-auc:0.89018\n",
      "[750]\ttrain-auc:0.95791\tvalid-auc:0.89025\n",
      "[800]\ttrain-auc:0.96039\tvalid-auc:0.89058\n",
      "[850]\ttrain-auc:0.96254\tvalid-auc:0.89050\n",
      "[900]\ttrain-auc:0.96466\tvalid-auc:0.89048\n",
      "[950]\ttrain-auc:0.96669\tvalid-auc:0.89045\n",
      "[984]\ttrain-auc:0.96787\tvalid-auc:0.89045\n",
      "0.6542404473438956\n",
      "{'f3': 47.4102790139748, 'f159': 19.76175831175372, 'f16': 18.477947307461537, 'f33': 9.365249544391311, 'f0': 11.493117304605054, 'f5': 18.488043080980386, 'f9': 4.983803367049999, 'f36': 5.488285822301449, 'f31': 5.82362062174759, 'f32': 8.09374784090206, 'f160': 6.320390557722223, 'f156': 10.305089473414634, 'f15': 4.893999525648648, 'f46': 47.9442252654054, 'f6': 40.46232786116101, 'f10': 4.154450652699635, 'f2': 6.819042266181415, 'f1': 8.130874461018692, 'f28': 5.6817846394173595, 'f44': 7.425153124716131, 'f66': 5.8271287267266665, 'f29': 5.107976316139534, 'f27': 6.393976355131246, 'f35': 5.485723197664004, 'f47': 47.250953675000005, 'f11': 6.712723969400002, 'f91': 6.346267181888889, 'f37': 5.413604976039715, 'f41': 5.433060154279599, 'f52': 4.842007851499999, 'f155': 4.5338583106999994, 'f40': 5.790754188922329, 'f39': 4.980982035833758, 'f22': 4.570448917149808, 'f26': 4.9725694796914315, 'f17': 5.377991056882631, 'f152': 5.480807277493331, 'f38': 4.9258906444774055, 'f76': 6.500897726666667, 'f34': 6.782271274104765, 'f18': 7.622888221594205, 'f23': 4.817161824746156, 'f77': 3.597044395153846, 'f57': 6.758223410285714, 'f12': 4.450566194857629, 'f69': 11.415336984333335, 'f8': 5.247647122325728, 'f4': 5.441997487464238, 'f83': 8.382683478533334, 'f45': 4.614610851232559, 'f126': 4.447345735666667, 'f24': 4.577786667868967, 'f150': 9.186135910227271, 'f68': 8.36487357619048, 'f19': 7.700470672074243, 'f59': 5.961209273214284, 'f21': 4.925960408206733, 'f20': 5.162332792134076, 'f61': 4.181125520970589, 'f58': 5.31622482, 'f67': 5.284925560344828, 'f64': 14.503253632666672, 'f43': 4.788059219380954, 'f157': 5.734206720555555, 'f123': 7.097310638571429, 'f25': 4.858292715680002, 'f54': 5.7595505254545465, 'f104': 2.986235107357142, 'f42': 5.2456234361682235, 'f151': 12.409149383, 'f73': 5.018416645, 'f13': 4.88499263484, 'f115': 6.486173417222223, 'f95': 3.683491906, 'f88': 5.074521249230769, 'f92': 3.4471435885714286, 'f7': 5.0128220785714275, 'f99': 5.921269363076923, 'f81': 5.905675680227272, 'f153': 7.106674797499999, 'f62': 4.2142459400000005, 'f100': 4.647104313157895, 'f85': 8.106485157272727, 'f14': 4.434299179400002, 'f103': 6.090639201368423, 'f75': 3.9982208972727267, 'f72': 5.757452558666665, 'f106': 3.6407506883333327, 'f80': 3.42347431, 'f63': 4.717172862, 'f112': 4.171241348461537, 'f94': 4.226464000399999, 'f53': 6.103859900000001, 'f70': 4.076452465, 'f84': 5.6094146026315785, 'f82': 6.3400681025, 'f30': 4.115050353076923, 'f74': 4.150133777647059, 'f86': 5.462394, 'f55': 4.61796174, 'f60': 1.8910185808999997, 'f102': 3.75806060325, 'f148': 5.376807145071429, 'f101': 3.9609890299999995, 'f127': 5.13348389, 'f114': 4.2138068685, 'f107': 4.1558008343749995, 'f139': 4.883973835000001, 'f138': 3.8140345799999995, 'f98': 4.633429704999999, 'f71': 4.4493669275, 'f149': 5.53108597, 'f161': 3.221845539090909, 'f65': 3.098726985, 'f124': 3.3945051033333336, 'f109': 4.46873325, 'f51': 3.43136024, 'f116': 5.86465788, 'f78': 5.5219350557142866, 'f125': 4.2990562924999995, 'f122': 8.24662971, 'f121': 2.861426193333333, 'f118': 3.6474967, 'f105': 2.1100151387499997}\n",
      "[09:32:14] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.81068\tvalid-auc:0.80852\n",
      "[50]\ttrain-auc:0.88231\tvalid-auc:0.87118\n",
      "[100]\ttrain-auc:0.88705\tvalid-auc:0.87445\n",
      "[150]\ttrain-auc:0.89485\tvalid-auc:0.87796\n",
      "[200]\ttrain-auc:0.90498\tvalid-auc:0.88203\n",
      "[250]\ttrain-auc:0.91382\tvalid-auc:0.88449\n",
      "[300]\ttrain-auc:0.92075\tvalid-auc:0.88562\n",
      "[350]\ttrain-auc:0.92648\tvalid-auc:0.88638\n",
      "[400]\ttrain-auc:0.93142\tvalid-auc:0.88671\n",
      "[450]\ttrain-auc:0.93578\tvalid-auc:0.88701\n",
      "[500]\ttrain-auc:0.93979\tvalid-auc:0.88748\n",
      "[550]\ttrain-auc:0.94344\tvalid-auc:0.88754\n",
      "[600]\ttrain-auc:0.94693\tvalid-auc:0.88729\n",
      "[612]\ttrain-auc:0.94768\tvalid-auc:0.88768\n",
      "1.3258135844184127\n",
      "{'f3': 65.19082195013054, 'f16': 17.84860753523129, 'f5': 24.703436182213945, 'f33': 11.652610609827587, 'f155': 5.3545653294285716, 'f0': 13.155109476272735, 'f159': 25.059211455104187, 'f31': 5.507288518789695, 'f28': 6.30668260521053, 'f27': 6.976637595207315, 'f36': 6.17185673141304, 'f46': 47.42187399340659, 'f32': 9.175409283419297, 'f9': 5.48014111177857, 'f40': 6.872057985152072, 'f160': 13.065578816250001, 'f35': 6.070640311136364, 'f11': 9.18874068861905, 'f6': 43.9026731078001, 'f37': 5.883373563553572, 'f1': 11.620902210771595, 'f2': 8.57891541973642, 'f70': 6.4186539333749995, 'f66': 8.559803339238092, 'f47': 55.79059438571428, 'f10': 4.047563812671642, 'f22': 5.453695812781253, 'f140': 3.5985622406666664, 'f26': 5.308060152583334, 'f44': 8.470443217892855, 'f68': 10.867277490941175, 'f83': 11.325428853285718, 'f57': 8.048558889448277, 'f17': 5.6185019423983045, 'f39': 5.6408451515625, 'f21': 5.6670066966594215, 'f38': 6.324632552799025, 'f24': 6.084084761770833, 'f156': 12.469431023333334, 'f81': 9.2026392275, 'f34': 8.003861994577779, 'f19': 5.5955162478902425, 'f8': 6.20073698978667, 'f45': 5.318844322758621, 'f153': 6.066037824714285, 'f13': 5.616252430770968, 'f69': 13.695088686129033, 'f84': 4.637835637633334, 'f4': 6.8326061711813955, 'f125': 3.6372016659999997, 'f152': 7.885259944473688, 'f59': 7.139824545, 'f18': 9.017763232380954, 'f15': 5.302570198891568, 'f77': 3.226396220923078, 'f150': 11.675223533150687, 'f67': 7.5971436984210525, 'f157': 5.625965697619047, 'f92': 8.526836862500002, 'f20': 6.078248363735715, 'f60': 3.8861368042857145, 'f43': 5.241621075648648, 'f54': 4.732356565642857, 'f98': 3.715587641, 'f7': 5.485112822624999, 'f23': 4.6006024417678555, 'f94': 4.570650755, 'f75': 5.1835261130769235, 'f41': 6.207763144916083, 'f29': 6.024178742272728, 'f42': 5.877585929523808, 'f101': 3.848706674, 'f25': 5.732511127826086, 'f104': 3.0193997219166664, 'f151': 10.0457207625, 'f12': 4.9377830037249995, 'f74': 4.824226747142857, 'f64': 10.071336188124997, 'f72': 5.321168025555555, 'f14': 6.149976998249999, 'f71': 5.22270876125, 'f61': 7.284146685454547, 'f100': 3.893618518285714, 'f91': 9.403451511428571, 'f126': 5.40945435, 'f99': 7.395011565925925, 'f148': 4.10165262, 'f103': 5.819850878181819, 'f78': 5.671373683333333, 'f86': 4.639048862, 'f102': 6.59119964, 'f88': 5.598850250000001, 'f73': 5.903357368571428, 'f116': 5.140823283333333, 'f48': 3.6541872, 'f55': 5.053503275, 'f121': 7.287489128, 'f52': 3.7980992000000007, 'f124': 3.73131084, 'f114': 5.70192325, 'f112': 4.313798405454546, 'f139': 7.499132272500001, 'f122': 8.68234561, 'f89': 4.3394901, 'f53': 4.25080669075, 'f90': 4.679860012857142, 'f30': 5.65605664, 'f62': 4.406908968333333, 'f106': 5.34048367, 'f128': 5.05756283, 'f149': 6.11007881, 'f109': 4.65211916, 'f123': 2.9651938280000003, 'f85': 5.4681174175, 'f118': 4.94955063, 'f82': 5.1159668, 'f95': 6.90749407, 'f58': 5.280920505, 'f63': 3.739866375, 'f107': 3.6711576, 'f138': 3.11126804}\n",
      "[09:32:36] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.82507\tvalid-auc:0.81021\n",
      "[50]\ttrain-auc:0.88353\tvalid-auc:0.86308\n",
      "[100]\ttrain-auc:0.88998\tvalid-auc:0.86730\n",
      "[150]\ttrain-auc:0.89854\tvalid-auc:0.87072\n",
      "[200]\ttrain-auc:0.90796\tvalid-auc:0.87521\n",
      "[250]\ttrain-auc:0.91598\tvalid-auc:0.87725\n",
      "[300]\ttrain-auc:0.92241\tvalid-auc:0.87853\n",
      "[350]\ttrain-auc:0.92845\tvalid-auc:0.87975\n",
      "[400]\ttrain-auc:0.93308\tvalid-auc:0.88087\n",
      "[450]\ttrain-auc:0.93773\tvalid-auc:0.88173\n",
      "[500]\ttrain-auc:0.94176\tvalid-auc:0.88223\n",
      "[550]\ttrain-auc:0.94523\tvalid-auc:0.88264\n",
      "[600]\ttrain-auc:0.94857\tvalid-auc:0.88272\n",
      "[650]\ttrain-auc:0.95188\tvalid-auc:0.88321\n",
      "[700]\ttrain-auc:0.95442\tvalid-auc:0.88386\n",
      "[750]\ttrain-auc:0.95723\tvalid-auc:0.88414\n",
      "[800]\ttrain-auc:0.95964\tvalid-auc:0.88436\n",
      "[850]\ttrain-auc:0.96214\tvalid-auc:0.88423\n",
      "[900]\ttrain-auc:0.96443\tvalid-auc:0.88426\n",
      "[912]\ttrain-auc:0.96483\tvalid-auc:0.88417\n",
      "1.9774787509350644\n",
      "{'f3': 54.26690946785127, 'f159': 20.596944689327735, 'f16': 18.454945037184213, 'f33': 10.457221202966734, 'f0': 11.898896066797397, 'f5': 14.452818339075161, 'f10': 4.350116161525422, 'f32': 8.073157079164055, 'f40': 6.407749471216489, 'f4': 5.937643800383627, 'f68': 10.630939068710806, 'f36': 5.91992096395652, 'f160': 8.097700254407405, 'f35': 5.285579039529102, 'f46': 52.07865154267327, 'f9': 5.242285481427491, 'f22': 5.155073906133577, 'f6': 39.454455806834986, 'f1': 8.690795467702454, 'f66': 7.059286907692306, 'f27': 4.569542106743055, 'f37': 4.77752278616334, 'f8': 4.826160383441944, 'f11': 7.208826211266665, 'f2': 6.349279766351952, 'f84': 4.793816413149999, 'f28': 6.030012970808889, 'f47': 45.16494288, 'f44': 7.058593529848588, 'f31': 5.522490632607821, 'f18': 8.282256320384617, 'f138': 4.137216663999999, 'f38': 5.0529325838425425, 'f156': 10.092661526231035, 'f17': 5.255352700790001, 'f150': 10.348673141375, 'f23': 4.945011886564815, 'f157': 7.080381442307693, 'f148': 5.21764171725, 'f25': 6.208719525454544, 'f39': 5.1950457121401366, 'f45': 4.424845036836959, 'f41': 5.383062490041743, 'f21': 5.3737775270857115, 'f69': 7.335091491818182, 'f15': 4.91394184244951, 'f34': 7.568513529161618, 'f19': 6.38730060012069, 'f152': 7.085633388484848, 'f77': 3.3814318541428574, 'f149': 5.519247055, 'f70': 2.814758023875, 'f57': 8.877865630799995, 'f59': 7.072160056315789, 'f155': 4.471183251379311, 'f61': 5.909291292225, 'f153': 7.377740385555555, 'f72': 3.9005940289444445, 'f73': 3.858221213333333, 'f92': 5.243813102727273, 'f7': 5.033098272791304, 'f26': 4.6601916843582085, 'f64': 12.528528600823527, 'f24': 4.502148274942149, 'f43': 5.290051230259741, 'f81': 5.15800919353125, 'f67': 5.950413091578948, 'f83': 8.129254971090909, 'f20': 5.975136801036459, 'f29': 5.4266449458421055, 'f74': 3.412206427857143, 'f85': 3.3747147560000004, 'f102': 5.0574461702, 'f13': 4.456249549745098, 'f104': 3.8387412739999998, 'f151': 10.976212532142856, 'f42': 5.369867142435895, 'f12': 4.615343120273381, 'f124': 3.4722139033333335, 'f99': 5.199338862777778, 'f86': 3.8614310625000003, 'f89': 6.246788503333334, 'f82': 5.745767356999999, 'f103': 6.355850991612903, 'f91': 5.176396982857143, 'f101': 4.692371592705882, 'f52': 4.9673964999999995, 'f75': 3.812708898, 'f115': 5.496594054285715, 'f14': 4.530582310874999, 'f76': 10.661837595, 'f71': 4.497227091666667, 'f54': 4.902940403545455, 'f62': 2.8167799299999996, 'f94': 3.7490979704444447, 'f112': 4.454593240833334, 'f78': 4.0433579075, 'f100': 4.4699466626666675, 'f95': 3.9473965640000004, 'f53': 4.295240615999999, 'f123': 4.673891785, 'f140': 5.67416, 'f80': 5.69470406, 'f63': 5.074188234285715, 'f126': 7.11083984, 'f114': 2.701826201555556, 'f30': 4.061406337692309, 'f88': 4.693195739999999, 'f121': 5.643092059999999, 'f60': 3.25580902, 'f51': 4.707198146666666, 'f93': 6.67581177, 'f161': 4.014501306666666, 'f109': 2.59567571, 'f58': 5.541961430000001, 'f96': 6.81252193, 'f65': 3.547543478, 'f98': 4.5363011349999995, 'f105': 2.82913970875, 'f90': 2.87894654, 'f119': 3.3184714324999995, 'f106': 4.16841078, 'f116': 2.68345857, 'f128': 3.38305497, 'f55': 1.30029011}\n",
      "[09:33:31] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.80933\tvalid-auc:0.78163\n",
      "[50]\ttrain-auc:0.87675\tvalid-auc:0.86405\n",
      "[100]\ttrain-auc:0.88580\tvalid-auc:0.87204\n",
      "[150]\ttrain-auc:0.89430\tvalid-auc:0.87755\n",
      "[200]\ttrain-auc:0.90510\tvalid-auc:0.88365\n",
      "[250]\ttrain-auc:0.91335\tvalid-auc:0.88646\n",
      "[300]\ttrain-auc:0.92050\tvalid-auc:0.88861\n",
      "[350]\ttrain-auc:0.92631\tvalid-auc:0.88954\n",
      "[400]\ttrain-auc:0.93143\tvalid-auc:0.89007\n",
      "[450]\ttrain-auc:0.93589\tvalid-auc:0.89047\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a0fc99b5e15b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0md_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mxgb_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \"\"\"\n\u001b[0;32m--> 189\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset name should not contain `-`'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# into datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;31m# split up `test-error:0.1234`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1563\u001b[0m         \u001b[0mevnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m         _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1566\u001b[0m                                               \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_train # apriori, analise de fator\n",
    "df_train # apriori, analise de fator"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var10</th>\n",
       "      <th>...</th>\n",
       "      <th>var51_0</th>\n",
       "      <th>var51_1</th>\n",
       "      <th>var53_0</th>\n",
       "      <th>var53_1</th>\n",
       "      <th>var53_2</th>\n",
       "      <th>var53_3</th>\n",
       "      <th>var54_0</th>\n",
       "      <th>var54_1</th>\n",
       "      <th>var54_2</th>\n",
       "      <th>var54_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2853</td>\n",
       "      <td>29442</td>\n",
       "      <td>1386</td>\n",
       "      <td>2435</td>\n",
       "      <td>35</td>\n",
       "      <td>-999</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1986</td>\n",
       "      <td>13684</td>\n",
       "      <td>7189</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>17</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1019</td>\n",
       "      <td>10232</td>\n",
       "      <td>678</td>\n",
       "      <td>791</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>1751</td>\n",
       "      <td>2689</td>\n",
       "      <td>8235</td>\n",
       "      <td>1042</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>2262</td>\n",
       "      <td>29428</td>\n",
       "      <td>6031</td>\n",
       "      <td>304</td>\n",
       "      <td>16</td>\n",
       "      <td>-999</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14118</th>\n",
       "      <td>35295</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>2511</td>\n",
       "      <td>28766</td>\n",
       "      <td>1109</td>\n",
       "      <td>2094</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14119</th>\n",
       "      <td>35296</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1114</td>\n",
       "      <td>-999</td>\n",
       "      <td>6376</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>27</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14120</th>\n",
       "      <td>35301</td>\n",
       "      <td>27</td>\n",
       "      <td>44</td>\n",
       "      <td>1786</td>\n",
       "      <td>23761</td>\n",
       "      <td>9048</td>\n",
       "      <td>623</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14121</th>\n",
       "      <td>35304</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>210</td>\n",
       "      <td>19593</td>\n",
       "      <td>3634</td>\n",
       "      <td>2453</td>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14122</th>\n",
       "      <td>35306</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>568</td>\n",
       "      <td>4612</td>\n",
       "      <td>4982</td>\n",
       "      <td>1438</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14123 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  var1  var2  var3   var4  var5  var6  var7  var8  var10  ...  \\\n",
       "0          1    18    19  2853  29442  1386  2435    35  -999     63  ...   \n",
       "1          8     4   110  1986  13684  7189  -999  -999    17     63  ...   \n",
       "2         30     0    39  1019  10232   678   791    16  -999     63  ...   \n",
       "3         43    20    39  1751   2689  8235  1042    13    10     14  ...   \n",
       "4         46     7    44  2262  29428  6031   304    16  -999     63  ...   \n",
       "...      ...   ...   ...   ...    ...   ...   ...   ...   ...    ...  ...   \n",
       "14118  35295     4    39  2511  28766  1109  2094    31    24   -999  ...   \n",
       "14119  35296    19   129  1114   -999  6376  -999  -999    27   -999  ...   \n",
       "14120  35301    27    44  1786  23761  9048   623    35    27     14  ...   \n",
       "14121  35304     4    89   210  19593  3634  2453    35    27     63  ...   \n",
       "14122  35306    21    53   568   4612  4982  1438    33    25     63  ...   \n",
       "\n",
       "       var51_0  var51_1  var53_0  var53_1  var53_2  var53_3  var54_0  var54_1  \\\n",
       "0            1        0        0        1        0        0        0        1   \n",
       "1            1        0        0        1        0        0        0        1   \n",
       "2            1        0        0        1        0        0        0        1   \n",
       "3            1        0        0        1        0        0        0        1   \n",
       "4            1        0        0        1        0        0        0        1   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "14118        1        0        0        0        1        0        0        0   \n",
       "14119        1        0        1        0        0        0        1        0   \n",
       "14120        1        0        0        0        1        0        0        0   \n",
       "14121        0        1        0        0        1        0        0        0   \n",
       "14122        1        0        0        0        1        0        0        0   \n",
       "\n",
       "       var54_2  var54_3  \n",
       "0            0        0  \n",
       "1            0        0  \n",
       "2            0        0  \n",
       "3            0        0  \n",
       "4            0        0  \n",
       "...        ...      ...  \n",
       "14118        1        0  \n",
       "14119        0        0  \n",
       "14120        1        0  \n",
       "14121        1        0  \n",
       "14122        1        0  \n",
       "\n",
       "[14123 rows x 165 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(err/5) #print(err/4) #6711266\n",
    "print(err2/5) #print(err/4) #6711266\n",
    "print(err3/5) #print(err/4) #6711266\n",
    "print(err4/5) #print(err/4) #6711266\n",
    "print(err5/5) #print(err/4) #6711266\n",
    "print(errLL/5) #print(err/4) #6711266"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6711176137096642\n",
      "0.6711176137096642\n",
      "0.6711176137096642\n",
      "0.6711176137096642\n",
      "0.6711176137096642\n",
      "0.3075985331784782\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "output = pd.DataFrame({'id': id_test, 'predicted': preds})\n",
    "\n",
    "output.to_csv(\"../data/output/proba/{}-foldCV_avg_sub_dummy_dist_cutpoint{}_error{}_logloss{}.csv\".format(K,cutPoint, err/5, errLL/5), index=False)   \n",
    "output['predicted'][output['predicted'] > cutPoint] = 1\n",
    "output['predicted'][output['predicted'] != 1] = 0\n",
    "output['predicted'] = output['predicted'].astype(int)\n",
    "output.to_csv(\"../data/output/{}-foldCV_avg_sub_dummy_dist_cutpoint{}_error{}_logloss{}.csv\".format(K,cutPoint, err/5, errLL/5), index=False)   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-7-706f6c019a63>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] > cutPoint] = 1\n",
      "<ipython-input-7-706f6c019a63>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] != 1] = 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "sub = pd.read_csv(\"./5-foldCV_avg_sub_36_dummy.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "sub[\"v\"] = output[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "sub[\"v2\"] = sub[\"v\"] - sub[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "sub[sub[\"v2\"] != 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "      <th>v</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, predicted, v, v2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "119"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}