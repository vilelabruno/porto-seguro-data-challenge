{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "target_train = df_train['y'].values\n",
    "id_test = df_test['id'].values\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#dummies = [\"var9\", \"var18\", \"var22\", \"var23\", \"var24\", \"var25\", \"var27\", \"var29\", \"var30\", \"var31\", \"var33\", \"var39\", \"var41\", \"var44\", \"var47\", \"var48\", \"var49\", \"var50\", \"var51\", \"var53\", \"var54\"]\n",
    "#\n",
    "#for col in dummies: # 100\n",
    "#    df_train = pd.get_dummies(df_train, columns=[col])\n",
    "#    df_test = pd.get_dummies(df_test, columns=[col])\n",
    "#for col in df_test.columns:\n",
    "#    \n",
    "#    if col not in df_train.columns:\n",
    "#        df_train[col] = 0\n",
    "df_train[\"var22\"] = df_train[\"var22\"].astype(str)\n",
    "df_train[\"var23\"] = df_train[\"var23\"].astype(str)\n",
    "df_train[\"var24\"] = df_train[\"var24\"].astype(str)\n",
    "df_train[\"histProd\"] = df_train[\"var22\"] + \"-\" +df_train[\"var23\"] + \"-\" +df_train[\"var24\"] + \"-\" \n",
    "df_test[\"var22\"] = df_test[\"var22\"].astype(str)\n",
    "df_test[\"var23\"] = df_test[\"var23\"].astype(str)\n",
    "df_test[\"var24\"] = df_test[\"var24\"].astype(str)\n",
    "df_test[\"histProd\"] = df_test[\"var22\"] + \"-\" +df_test[\"var23\"] + \"-\" +df_test[\"var24\"] + \"-\" \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_train[\"histProd\"], _ = pd.factorize(df_train[\"histProd\"])\n",
    "df_test[\"histProd\"], _ = pd.factorize(df_test[\"histProd\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dummies = 20\n",
    "\n",
    "for col in df_test.columns: # 100\n",
    "    if (len(df_test[col].unique()) < dummies) and (len(df_test[col].unique()) == len(df_train[col].unique())):\n",
    "        df_train = pd.get_dummies(df_train, columns=[col])\n",
    "        df_test = pd.get_dummies(df_test, columns=[col])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train = np.array(df_train.drop(['y','id'], axis = 1))\n",
    "test = np.array(df_test.drop(['id'], axis = 1))\n",
    "\n",
    "xgb_preds = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 3228, shuffle = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "def xgb_f1(y, t, threshold=0.5):\n",
    "    t = t.get_label()\n",
    "    y_bin = (y > threshold).astype(int) # works for both type(y) == <class 'numpy.ndarray'> and type(y) == <class 'pandas.core.series.Series'>\n",
    "    return 'f1',f1_score(t,y_bin)\n",
    "err = 0\n",
    "err2 = 0\n",
    "err3 = 0\n",
    "err4 = 0\n",
    "err5 = 0\n",
    "errLL = 0\n",
    "cutPoint = 0.34\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train_X, valid_X = train[train_index], train[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "    #xgb_params = {'eta': 0.11, 'max_depth': 5, 'subsample': 0.4, 'colsample_bytree': 0.4, 'objective': 'binary:logistic', 'min_child_weight': 15, 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, maximize=True, verbose_eval=50, early_stopping_rounds=100)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    pG = model.predict(d_valid)\n",
    "\n",
    "    errLL += log_loss(valid_y, pG)\n",
    "    p = pG\n",
    "    p[p > cutPoint] = 1\n",
    "    p[p != 1] = 0\n",
    "    err += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err2 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err3 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err4 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err5 += f1_score(valid_y, p)\n",
    "    print(err)\n",
    "    print(model.get_score(importance_type='gain'))\n",
    "    xgb_preds.append(list(xgb_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17:58:51] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84887\tvalid-auc:0.82489\n",
      "[50]\ttrain-auc:0.87772\tvalid-auc:0.85538\n",
      "[100]\ttrain-auc:0.88556\tvalid-auc:0.86293\n",
      "[150]\ttrain-auc:0.89544\tvalid-auc:0.87021\n",
      "[200]\ttrain-auc:0.90606\tvalid-auc:0.87672\n",
      "[250]\ttrain-auc:0.91451\tvalid-auc:0.88031\n",
      "[300]\ttrain-auc:0.92182\tvalid-auc:0.88290\n",
      "[350]\ttrain-auc:0.92763\tvalid-auc:0.88538\n",
      "[400]\ttrain-auc:0.93290\tvalid-auc:0.88678\n",
      "[450]\ttrain-auc:0.93749\tvalid-auc:0.88750\n",
      "[500]\ttrain-auc:0.94137\tvalid-auc:0.88818\n",
      "[550]\ttrain-auc:0.94536\tvalid-auc:0.88869\n",
      "[600]\ttrain-auc:0.94897\tvalid-auc:0.88878\n",
      "[650]\ttrain-auc:0.95197\tvalid-auc:0.88941\n",
      "[700]\ttrain-auc:0.95488\tvalid-auc:0.88993\n",
      "[750]\ttrain-auc:0.95768\tvalid-auc:0.89051\n",
      "[800]\ttrain-auc:0.96016\tvalid-auc:0.89078\n",
      "[850]\ttrain-auc:0.96240\tvalid-auc:0.89066\n",
      "[900]\ttrain-auc:0.96438\tvalid-auc:0.89069\n",
      "[933]\ttrain-auc:0.96582\tvalid-auc:0.89062\n",
      "0.647912885662432\n",
      "{'f3': 48.99830323002721, 'f7': 40.14768372922039, 'f5': 17.0375762367877, 'f11': 4.110764228051466, 'f1': 7.626158938885004, 'f17': 10.74378986896875, 'f34': 9.966323689017745, 'f0': 11.344631936982395, 'f45': 7.902995114792872, 'f161': 17.360451142138885, 'f2': 7.031943104524473, 'f162': 6.789428471111112, 'f12': 7.302402719430556, 'f10': 4.914787997344571, 'f33': 8.514540783080763, 'f32': 5.8918076568674005, 'f16': 5.140318107242611, 'f6': 30.76659048709529, 'f29': 5.763778362389611, 'f38': 5.41004079988754, 'f158': 11.446052395294123, 'f128': 2.5618424405, 'f36': 5.635826499288468, 'f37': 5.751700863808249, 'f42': 5.288692191071269, 'f18': 5.7727345054714325, 'f9': 5.575448972931766, 'f27': 5.216896378683453, 'f154': 5.535084290861113, 'f40': 5.0466910557290445, 'f30': 5.956535944651161, 'f41': 5.842365601190463, 'f4': 5.376798981691575, 'f59': 6.112483244192308, 'f71': 12.459636800800002, 'f157': 6.727087401249999, 'f39': 5.0901134928885945, 'f35': 7.217906338374998, 'f20': 7.633462140701755, 'f23': 4.658010387698183, 'f13': 5.022465826095745, 'f54': 4.961782296111109, 'f46': 4.643839790724491, 'f79': 4.030152588999999, 'f19': 7.525641439666669, 'f69': 6.075513794642857, 'f61': 5.491220328333333, 'f28': 6.614866208353024, 'f26': 5.0543964356122455, 'f66': 12.825502861428577, 'f85': 8.295257456805558, 'f22': 4.751724651458288, 'f24': 4.841128081314841, 'f8': 6.27392731, 'f93': 4.92346864925, 'f21': 5.14005861841886, 'f47': 5.317264955223024, 'f25': 4.802832657499999, 'f152': 9.94410125642857, 'f117': 6.050869106875001, 'f56': 5.363355940909091, 'f80': 6.076780182857143, 'f43': 5.6825811278571425, 'f70': 9.322382952676058, 'f87': 7.718031135999999, 'f60': 5.055547475, 'f44': 5.16779798467742, 'f63': 4.34124616081081, 'f116': 3.4561106088, 'f91': 5.9092738525, 'f105': 6.445717817857141, 'f159': 5.209623772222224, 'f106': 3.4030305507391314, 'f51': 5.868723573846154, 'f50': 4.390301386666667, 'f75': 4.795955372, 'f155': 7.93644562625, 'f103': 4.371448967111111, 'f102': 4.877838135555555, 'f83': 5.9400963042857144, 'f97': 2.8478449583333334, 'f14': 4.268538009744186, 'f153': 6.923658115384615, 'f68': 5.862969522166666, 'f101': 5.3549858872727265, 'f49': 5.249342417105263, 'f125': 7.04811344, 'f15': 4.857606023571429, 'f74': 4.8159725286842106, 'f96': 5.1232570314285715, 'f72': 3.8816459179999994, 'f86': 5.162860670000001, 'f77': 3.693961774642857, 'f104': 4.060423441428571, 'f90': 4.97764751, 'f76': 4.3915874975, 'f65': 5.6286366459999995, 'f88': 4.66698249, 'f62': 3.3147282803, 'f57': 6.038918495, 'f114': 4.932369732857144, 'f64': 4.6698143493333335, 'f31': 4.452969903157895, 'f141': 4.2669297450000006, 'f123': 4.805817923333334, 'f100': 3.292418292, 'f151': 5.390429180000001, 'f94': 5.981231214999999, 'f84': 7.764706815714285, 'f150': 5.788646278750001, 'f129': 5.23854637, 'f111': 4.389294466666667, 'f108': 3.1494345675, 'f109': 3.92483613, 'f127': 6.1617765425, 'f142': 6.1844306, 'f163': 3.156425357, 'f118': 5.67256689, 'f55': 6.149656775, 'f78': 2.49574244, 'f107': 2.151701768888889, 'f82': 4.76205349, 'f140': 2.1220386}\n",
      "[18:19:26] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84290\tvalid-auc:0.84235\n",
      "[50]\ttrain-auc:0.87748\tvalid-auc:0.86378\n",
      "[100]\ttrain-auc:0.88479\tvalid-auc:0.87041\n",
      "[150]\ttrain-auc:0.89509\tvalid-auc:0.87607\n",
      "[200]\ttrain-auc:0.90578\tvalid-auc:0.88064\n",
      "[250]\ttrain-auc:0.91430\tvalid-auc:0.88294\n",
      "[300]\ttrain-auc:0.92161\tvalid-auc:0.88379\n",
      "[350]\ttrain-auc:0.92727\tvalid-auc:0.88470\n",
      "[400]\ttrain-auc:0.93246\tvalid-auc:0.88537\n",
      "[450]\ttrain-auc:0.93672\tvalid-auc:0.88523\n",
      "[500]\ttrain-auc:0.94034\tvalid-auc:0.88558\n",
      "[550]\ttrain-auc:0.94405\tvalid-auc:0.88594\n",
      "[600]\ttrain-auc:0.94735\tvalid-auc:0.88617\n",
      "[650]\ttrain-auc:0.95042\tvalid-auc:0.88618\n",
      "[700]\ttrain-auc:0.95333\tvalid-auc:0.88634\n",
      "[711]\ttrain-auc:0.95395\tvalid-auc:0.88630\n",
      "1.3151790727127917\n",
      "{'f3': 59.14399234372834, 'f7': 40.43183277374557, 'f5': 19.453837011096308, 'f32': 5.729498980755933, 'f1': 10.834555094357139, 'f17': 10.87429245763158, 'f34': 11.300359337956777, 'f28': 6.779632320604836, 'f2': 7.82115791042139, 'f0': 12.67962802460201, 'f33': 8.93202821595183, 'f40': 5.733035226974897, 'f161': 20.285395987028032, 'f41': 6.479435485704612, 'f162': 11.887536482903224, 'f36': 5.868704539441978, 'f37': 6.434829012233918, 'f6': 30.26003813456271, 'f72': 6.397126300000001, 'f29': 6.064334227513772, 'f18': 5.609631386604836, 'f38': 5.335470563306012, 'f158': 12.108982651428573, 'f35': 7.612384189361906, 'f128': 0.310180664, 'f22': 5.429128537015706, 'f11': 4.781241603189397, 'f12': 7.781805202347825, 'f42': 5.621314068351647, 'f61': 6.606301679545456, 'f157': 7.1013554517391295, 'f85': 10.744922294, 'f45': 7.505635378848173, 'f9': 6.140147417776535, 'f27': 5.423404771976473, 'f59': 7.39284770884, 'f19': 6.534716828571427, 'f16': 5.230634195009089, 'f86': 4.684248837133333, 'f25': 5.338611373771075, 'f83': 7.233508677475001, 'f71': 15.266791156785713, 'f4': 6.289371721812525, 'f56': 3.9943037216666664, 'f48': 4.75439072, 'f23': 5.785300657106598, 'f39': 5.972157401284673, 'f70': 10.15303351625, 'f46': 5.0291021195147065, 'f14': 5.764368063484849, 'f84': 5.8184916975, 'f93': 5.986220413333333, 'f21': 5.848764081230769, 'f94': 7.3933459525, 'f43': 5.730219390177419, 'f155': 5.800881943333334, 'f101': 6.800182645454544, 'f150': 4.897371289111111, 'f10': 5.582723136142048, 'f69': 7.7956256875, 'f44': 5.234604926888889, 'f20': 5.21054630583582, 'f152': 10.627139232073171, 'f151': 7.710880755, 'f47': 5.7252563544601776, 'f30': 4.865562399444442, 'f153': 14.388465687000002, 'f79': 3.3703034760999997, 'f15': 5.139073034500001, 'f77': 4.428724273333333, 'f91': 3.802050113999999, 'f154': 7.6988643880555525, 'f24': 4.41740033089655, 'f159': 5.65511312, 'f13': 5.290867350824998, 'f63': 6.791876614137928, 'f106': 3.610125023647059, 'f68': 8.712497447777778, 'f66': 9.381134621874999, 'f125': 4.3868413, 'f74': 5.881466528571428, 'f114': 4.886309964285714, 'f116': 4.064188838375, 'f54': 3.766223428, 'f75': 4.094517110125, 'f65': 6.8239929675, 'f105': 5.49682443, 'f88': 4.327518700000001, 'f78': 7.5111202200000005, 'f62': 4.190972386, 'f118': 4.89595127, 'f51': 6.098131581571427, 'f140': 5.233807883333333, 'f100': 3.474727630142857, 'f141': 6.497324310000001, 'f126': 4.08670624, 'f57': 2.80448120775, 'f123': 7.586138009000001, 'f26': 5.468883172000001, 'f111': 4.377873038, 'f117': 9.17956352, 'f49': 5.430991988947369, 'f96': 7.667620664999999, 'f76': 10.222714665, 'f103': 3.4228852661818183, 'f127': 6.361689565000001, 'f8': 3.6547297233750005, 'f64': 5.064112937999999, 'f55': 5.688021852, 'f142': 6.9479670533333335, 'f104': 4.74439923, 'f124': 6.50848722, 'f87': 5.876176630000001, 'f102': 4.803534505, 'f73': 4.743548073333334, 'f97': 3.6981283725, 'f108': 4.27065301, 'f80': 6.067217945, 'f50': 3.62037182, 'f82': 5.53326845, 'f90': 3.89967513, 'f31': 5.0007569, 'f60': 5.69376945, 'f109': 3.55735683, 'f92': 3.6038487766666663, 'f120': 5.10010767, 'f163': 3.544658103333333}\n",
      "[18:36:53] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84511\tvalid-auc:0.82217\n",
      "[50]\ttrain-auc:0.87824\tvalid-auc:0.85815\n",
      "[100]\ttrain-auc:0.88705\tvalid-auc:0.86437\n",
      "[150]\ttrain-auc:0.89786\tvalid-auc:0.86909\n",
      "[200]\ttrain-auc:0.90827\tvalid-auc:0.87353\n",
      "[250]\ttrain-auc:0.91650\tvalid-auc:0.87637\n",
      "[300]\ttrain-auc:0.92310\tvalid-auc:0.87850\n",
      "[350]\ttrain-auc:0.92917\tvalid-auc:0.87953\n",
      "[400]\ttrain-auc:0.93405\tvalid-auc:0.88060\n",
      "[450]\ttrain-auc:0.93878\tvalid-auc:0.88148\n",
      "[500]\ttrain-auc:0.94272\tvalid-auc:0.88201\n",
      "[550]\ttrain-auc:0.94619\tvalid-auc:0.88228\n",
      "[600]\ttrain-auc:0.94942\tvalid-auc:0.88257\n",
      "[650]\ttrain-auc:0.95253\tvalid-auc:0.88333\n",
      "[700]\ttrain-auc:0.95496\tvalid-auc:0.88351\n",
      "[750]\ttrain-auc:0.95769\tvalid-auc:0.88367\n",
      "[800]\ttrain-auc:0.96008\tvalid-auc:0.88401\n",
      "[850]\ttrain-auc:0.96231\tvalid-auc:0.88402\n",
      "[900]\ttrain-auc:0.96442\tvalid-auc:0.88439\n",
      "[950]\ttrain-auc:0.96625\tvalid-auc:0.88450\n",
      "[1000]\ttrain-auc:0.96814\tvalid-auc:0.88458\n",
      "[1050]\ttrain-auc:0.97018\tvalid-auc:0.88436\n",
      "[1100]\ttrain-auc:0.97203\tvalid-auc:0.88453\n",
      "[1103]\ttrain-auc:0.97215\tvalid-auc:0.88449\n",
      "1.9689235661048623\n",
      "{'f3': 46.30256832466103, 'f7': 35.43764579194979, 'f5': 13.656499676055828, 'f38': 4.635544759449441, 'f1': 8.314107024594936, 'f17': 7.86549813574, 'f34': 9.757322804603946, 'f33': 7.563401877325451, 'f28': 4.5149821943770485, 'f0': 11.426441514158169, 'f161': 16.123555523260865, 'f10': 4.671703624177716, 'f23': 4.9562845026657, 'f6': 31.492326105075733, 'f162': 7.881416608333333, 'f45': 6.506993458470749, 'f9': 4.510841756012799, 'f2': 5.878019642856986, 'f158': 9.02374323288889, 'f36': 5.00884275709507, 'f32': 5.351263619762058, 'f70': 11.5276912371579, 'f11': 4.483766194230126, 'f37': 5.75465889972424, 'f41': 5.95641091843949, 'f4': 5.630152461308384, 'f12': 5.683125578418182, 'f24': 4.252088427875435, 'f18': 4.98832166386793, 'f86': 4.82880762072, 'f39': 4.875603733684595, 'f16': 4.703822386890962, 'f8': 5.18397478521739, 'f159': 7.1588400237037035, 'f20': 5.392125071193149, 'f150': 4.539510482125, 'f71': 11.84514411235294, 'f19': 7.965808604320987, 'f29': 5.682448866624469, 'f46': 4.220457304527684, 'f153': 9.018823049999998, 'f22': 5.176937041510918, 'f63': 5.5509524570833335, 'f154': 6.811294448059702, 'f35': 6.173290824017273, 'f72': 4.50056016375, 'f104': 3.5608349322666673, 'f157': 4.859685828709677, 'f40': 4.883883342363029, 'f152': 10.30060966032609, 'f80': 4.0330194, 'f47': 5.4415348591078425, 'f69': 4.748401230559999, 'f21': 5.367529359709161, 'f27': 4.73126237758896, 'f75': 3.922899983636363, 'f87': 3.2048193327272725, 'f61': 5.768012979409092, 'f68': 5.9659063471538465, 'f117': 5.469629589090911, 'f66': 9.671226260642856, 'f79': 3.2911670416666667, 'f83': 4.909580608258066, 'f30': 4.979835850939999, 'f85': 7.561094007328359, 'f56': 3.529471675, 'f42': 5.201231391726284, 'f25': 4.263585681771812, 'f106': 4.041076107368421, 'f123': 4.993262524285714, 'f59': 7.3729073575, 'f13': 4.218548596788082, 'f43': 4.744114931318682, 'f103': 3.9888296053888896, 'f15': 5.191302503659999, 'f105': 5.500001937512197, 'f126': 3.47467756, 'f101': 4.7638934407692295, 'f65': 5.588578176, 'f93': 5.403235458999999, 'f155': 6.637589426250001, 'f26': 5.374837998015623, 'f91': 6.4121806725, 'f14': 4.2910937384262295, 'f44': 4.880769363142857, 'f49': 5.5040117420588235, 'f94': 4.78947078090909, 'f96': 4.290207005882353, 'f51': 5.66696594523077, 'f102': 4.168368926153847, 'f54': 4.102388969333334, 'f64': 4.261027811666667, 'f55': 4.472180905, 'f77': 3.7793999524181827, 'f118': 4.50281572, 'f82': 4.474440096666666, 'f88': 4.03424963125, 'f73': 4.38519314, 'f142': 5.183831215, 'f124': 6.103003025, 'f140': 3.41942058375, 'f31': 4.098962623999999, 'f50': 4.4566981175, 'f62': 3.0247150658333335, 'f74': 4.5250171629375, 'f90': 4.601440746666667, 'f116': 3.7817680301111114, 'f60': 4.793524625, 'f125': 4.50588298, 'f97': 4.989356727500001, 'f57': 2.8496727349999995, 'f76': 4.3291277875, 'f163': 3.312018606153846, 'f95': 5.99672127, 'f151': 5.1066250816666665, 'f84': 4.686618431428572, 'f100': 3.5260855361111108, 'f141': 2.04250908, 'f130': 3.6789381500000005, 'f107': 2.4620876626666672, 'f121': 2.830015969, 'f114': 4.10338626, 'f53': 5.44936657, 'f108': 1.984096766, 'f67': 2.38845611, 'f120': 3.11050177, 'f127': 3.38445187, 'f109': 1.76113248, 'f111': 3.496499065}\n",
      "[19:01:01] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84547\tvalid-auc:0.84242\n",
      "[50]\ttrain-auc:0.87529\tvalid-auc:0.86540\n",
      "[100]\ttrain-auc:0.88384\tvalid-auc:0.87125\n",
      "[150]\ttrain-auc:0.89450\tvalid-auc:0.87748\n",
      "[200]\ttrain-auc:0.90558\tvalid-auc:0.88323\n",
      "[250]\ttrain-auc:0.91381\tvalid-auc:0.88545\n",
      "[300]\ttrain-auc:0.92067\tvalid-auc:0.88652\n",
      "[350]\ttrain-auc:0.92635\tvalid-auc:0.88779\n",
      "[400]\ttrain-auc:0.93130\tvalid-auc:0.88865\n",
      "[450]\ttrain-auc:0.93565\tvalid-auc:0.88942\n",
      "[500]\ttrain-auc:0.93958\tvalid-auc:0.88938\n",
      "[550]\ttrain-auc:0.94346\tvalid-auc:0.89009\n",
      "[600]\ttrain-auc:0.94697\tvalid-auc:0.89052\n",
      "[650]\ttrain-auc:0.95002\tvalid-auc:0.89102\n",
      "[700]\ttrain-auc:0.95269\tvalid-auc:0.89081\n",
      "[750]\ttrain-auc:0.95547\tvalid-auc:0.89113\n",
      "[772]\ttrain-auc:0.95661\tvalid-auc:0.89097\n",
      "2.662544410669103\n",
      "{'f3': 56.77258956447099, 'f7': 34.274948043494256, 'f5': 16.263565769414065, 'f38': 5.072086395200506, 'f17': 9.910385902863634, 'f34': 9.881935147220624, 'f0': 15.282615279651852, 'f1': 10.09081535746114, 'f33': 9.752574804667313, 'f29': 5.742765642724868, 'f6': 34.71281365341247, 'f32': 5.23752394951993, 'f2': 8.095451478834685, 'f45': 7.685398441753468, 'f27': 4.363536777247058, 'f161': 17.54026840142858, 'f154': 6.765526447304687, 'f41': 6.0463806330484715, 'f28': 4.492941908456522, 'f12': 9.379881368687503, 'f67': 4.4194401899999995, 'f158': 8.176594467033333, 'f157': 5.443898575285715, 'f37': 6.376920622305557, 'f162': 8.245370651724139, 'f11': 4.9310661886766445, 'f40': 5.33466939031621, 'f4': 5.787905842893453, 'f36': 6.473073504423361, 'f22': 5.221474837799855, 'f159': 7.744773321707317, 'f42': 5.3098844532888885, 'f18': 5.635226556534249, 'f155': 6.331911361875, 'f39': 5.731965455030641, 'f142': 3.49421692, 'f23': 6.252209571538288, 'f85': 8.73370145225397, 'f93': 6.647883128000001, 'f20': 7.410432008157896, 'f71': 11.101877946, 'f30': 5.269683837837836, 'f10': 5.727159367421322, 'f19': 6.155512223518518, 'f35': 7.228272155454545, 'f83': 7.903609595239998, 'f21': 5.180559042038962, 'f16': 5.493724795575423, 'f13': 5.524640434100774, 'f9': 5.397865284659092, 'f46': 4.561749595258065, 'f79': 5.2671548124375, 'f70': 8.762438022500001, 'f152': 9.852070635487808, 'f86': 5.623151605909091, 'f77': 4.369344392933333, 'f47': 5.687923013086021, 'f61': 6.94353261642857, 'f73': 6.363427331764706, 'f49': 5.349864121176471, 'f63': 4.689273963902438, 'f14': 5.07941486255, 'f96': 3.388238708333333, 'f87': 4.3587281927272725, 'f66': 12.638474333333331, 'f56': 4.323416407384615, 'f68': 4.233235222857144, 'f54': 4.63858562625, 'f25': 4.027426053295614, 'f24': 4.943489935499999, 'f50': 2.75251389, 'f80': 5.502876669285714, 'f15': 5.149543751421052, 'f102': 3.91096544375, 'f117': 6.031840665714285, 'f108': 4.4190484875000005, 'f44': 5.162221283145834, 'f59': 7.630650621428572, 'f106': 4.518899566470588, 'f153': 10.80051966, 'f69': 6.504167129230768, 'f8': 6.397305511666668, 'f43': 5.345619980833334, 'f90': 5.204112263529411, 'f78': 10.662959113333333, 'f74': 3.394196511142858, 'f97': 3.3947797171428573, 'f105': 5.7441979644500005, 'f60': 3.388874846666667, 'f72': 4.881803746249999, 'f103': 5.625271206, 'f26': 5.751825651911765, 'f126': 4.707269547499999, 'f100': 5.446356028125001, 'f140': 6.25014114, 'f53': 5.5458892550000005, 'f94': 5.448232507999999, 'f75': 3.79290470375, 'f64': 4.340465785, 'f114': 5.030897360000001, 'f116': 2.7766969225, 'f51': 5.260206687894738, 'f150': 3.261629102, 'f141': 5.35906601, 'f104': 4.935538383333334, 'f125': 3.923327366666667, 'f101': 4.118189216599999, 'f95': 2.60910892, 'f91': 6.47996616, 'f57': 5.786073843333334, 'f55': 4.386581260333333, 'f163': 4.247412523333334, 'f109': 3.9771401236363646, 'f31': 5.330695071666667, 'f62': 1.848573149, 'f76': 4.502409845000001, 'f84': 5.928151766666667, 'f123': 4.720293588571429, 'f88': 3.718334915, 'f111': 6.66809559, 'f128': 4.41278124}\n",
      "[19:17:18] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84037\tvalid-auc:0.85112\n",
      "[50]\ttrain-auc:0.87305\tvalid-auc:0.88015\n",
      "[100]\ttrain-auc:0.88135\tvalid-auc:0.88528\n",
      "[150]\ttrain-auc:0.89231\tvalid-auc:0.89108\n",
      "[200]\ttrain-auc:0.90290\tvalid-auc:0.89443\n",
      "[250]\ttrain-auc:0.91146\tvalid-auc:0.89713\n",
      "[300]\ttrain-auc:0.91837\tvalid-auc:0.89843\n",
      "[350]\ttrain-auc:0.92417\tvalid-auc:0.89974\n",
      "[400]\ttrain-auc:0.92938\tvalid-auc:0.90064\n",
      "[450]\ttrain-auc:0.93438\tvalid-auc:0.90098\n",
      "[500]\ttrain-auc:0.93877\tvalid-auc:0.90136\n",
      "[550]\ttrain-auc:0.94290\tvalid-auc:0.90120\n",
      "[600]\ttrain-auc:0.94643\tvalid-auc:0.90120\n",
      "[604]\ttrain-auc:0.94669\tvalid-auc:0.90113\n",
      "3.3587901444574992\n",
      "{'f3': 63.38581709661266, 'f7': 40.127709881223886, 'f5': 16.68843458908772, 'f38': 5.135747779112744, 'f17': 10.687117199933331, 'f34': 12.58159378100712, 'f1': 10.990646560117188, 'f42': 5.998289690612563, 'f22': 5.406972962232759, 'f6': 38.831684013980585, 'f2': 8.344600615558335, 'f0': 13.139681972832763, 'f161': 16.99367372314167, 'f41': 6.882015745770487, 'f37': 6.494955555043883, 'f33': 9.259753655006229, 'f158': 14.32857189375, 'f61': 6.972321763555555, 'f12': 10.671915376216214, 'f45': 7.912033589014712, 'f29': 6.410279882868964, 'f11': 5.708065603048779, 'f32': 5.829191294742856, 'f157': 7.416833691034482, 'f162': 10.520033586190477, 'f46': 5.617345565934427, 'f67': 4.23044395, 'f72': 6.741089692500001, 'f36': 6.110486873219566, 'f18': 6.765126965263157, 'f23': 6.498164481302821, 'f4': 6.718795308704174, 'f39': 5.837393222767439, 'f24': 5.218123499784313, 'f40': 5.950112918866667, 'f70': 10.305116299444443, 'f27': 5.96850373609756, 'f159': 9.404144406521738, 'f83': 7.461042340869567, 'f28': 6.678299435468751, 'f103': 3.8591851970454543, 'f86': 5.813455504999999, 'f59': 9.185222317419353, 'f16': 5.242592552263161, 'f19': 7.905205255625001, 'f43': 6.207865981607143, 'f85': 9.41677952581395, 'f21': 6.137795276132743, 'f8': 7.059064047583334, 'f44': 5.6547934810416685, 'f35': 7.965617860213334, 'f79': 5.01609685925, 'f9': 5.357572439707641, 'f13': 6.380901350166669, 'f62': 4.5573534935, 'f20': 6.962144369428571, 'f152': 11.6073837628, 'f71': 12.135277858636364, 'f66': 11.723800843999998, 'f10': 5.850446337563492, 'f69': 7.386752732068965, 'f154': 6.9820568910526335, 'f63': 5.336973288181818, 'f25': 4.596987872333334, 'f15': 6.739801091235295, 'f14': 4.9395841919249985, 'f30': 6.582833906296295, 'f128': 4.961976051666666, 'f155': 4.796667455, 'f47': 5.763099047692309, 'f153': 11.473722256249998, 'f94': 7.583146573333334, 'f56': 4.5544713733333335, 'f88': 4.6220349316, 'f108': 3.5337498966666665, 'f123': 5.6890636699999995, 'f106': 2.7284540918333335, 'f80': 6.843889665454546, 'f116': 4.540436427333333, 'f77': 4.687777947241379, 'f105': 7.581222096153848, 'f141': 6.150910852, 'f68': 6.850324006666667, 'f64': 4.9028006799999995, 'f93': 5.89190551888889, 'f54': 5.752532005, 'f55': 4.63182211, 'f100': 3.6936843406249995, 'f53': 5.440584975, 'f90': 5.45667260875, 'f96': 2.613016046333333, 'f75': 4.213971912250001, 'f91': 7.552097323333332, 'f50': 9.53391075, 'f102': 5.648732832857142, 'f163': 5.5430890349999995, 'f101': 5.979224602222222, 'f87': 3.36771393, 'f125': 4.464636565, 'f74': 5.546422005, 'f78': 8.043635846666668, 'f26': 5.98575464368421, 'f73': 3.756106375, 'f126': 5.0693215149999995, 'f76': 5.5548188675, 'f104': 3.200057985, 'f114': 7.193935585999999, 'f51': 5.9780044089999995, 'f117': 5.241318543333334, 'f31': 5.467757901666666, 'f49': 5.081384778333334, 'f150': 6.414786339999999, 'f97': 5.990657489999999, 'f60': 7.42458153, 'f92': 3.759539125, 'f140': 8.91170692}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_test[\"histProd\"]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0         0\n",
       "1         1\n",
       "2         2\n",
       "3         0\n",
       "4         3\n",
       "         ..\n",
       "21178     0\n",
       "21179    17\n",
       "21180     5\n",
       "21181     0\n",
       "21182     0\n",
       "Name: histProd, Length: 21183, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(err/5) #print(err/4) #6711266\n",
    "print(err2/5) #print(err/4) #6711266\n",
    "print(err3/5) #print(err/4) #6711266\n",
    "print(err4/5) #print(err/4) #6711266\n",
    "print(err5/5) #print(err/4) #6711266\n",
    "print(errLL/5) #print(err/4) #6711266"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6717580288914998\n",
      "0.6717580288914998\n",
      "0.6717580288914998\n",
      "0.6717580288914998\n",
      "0.6717580288914998\n",
      "0.30731110454339106\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+=xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "output = pd.DataFrame({'id': id_test, 'predicted': preds})\n",
    "output['predicted'][output['predicted'] > cutPoint] = 1\n",
    "output['predicted'][output['predicted'] != 1] = 0\n",
    "output['predicted'] = output['predicted'].astype(int)\n",
    "output.to_csv(\"../data/output/{}-foldCV_avg_sub_dummy_hist_cutpoint{}_error{}_logloss{}.csv\".format(K,cutPoint, err/5, errLL/5), index=False)   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-11-42f59777eed3>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] > cutPoint] = 1\n",
      "<ipython-input-11-42f59777eed3>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] != 1] = 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "sub = pd.read_csv(\"./5-foldCV_avg_sub_36_dummy.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "sub[\"v\"] = output[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "sub[\"v2\"] = sub[\"v\"] - sub[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "sub[sub[\"v2\"] != 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "      <th>v</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, predicted, v, v2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "119"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}