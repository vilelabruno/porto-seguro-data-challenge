{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "target_train = df_train['y'].values\n",
    "id_test = df_test['id'].values\n",
    "cols_to_drop = [\n",
    "    'id',\n",
    "    'y',\n",
    "]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#dummies = [\"var9\", \"var18\", \"var22\", \"var23\", \"var24\", \"var25\", \"var27\", \"var29\", \"var30\", \"var31\", \"var33\", \"var39\", \"var41\", \"var44\", \"var47\", \"var48\", \"var49\", \"var50\", \"var51\", \"var53\", \"var54\"]\n",
    "#\n",
    "#for col in dummies: # 100\n",
    "#    df_train = pd.get_dummies(df_train, columns=[col])\n",
    "#    df_test = pd.get_dummies(df_test, columns=[col])\n",
    "#for col in df_test.columns:\n",
    "#    \n",
    "#    if col not in df_train.columns:\n",
    "#        df_train[col] = 0\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dummies = 20\n",
    "\n",
    "for col in df_test.columns: # 100\n",
    "    if (len(df_test[col].unique()) < dummies) and (len(df_test[col].unique()) == len(df_train[col].unique())):\n",
    "        df_train = pd.get_dummies(df_train, columns=[col])\n",
    "        df_test = pd.get_dummies(df_test, columns=[col])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train = np.array(df_train.drop(['y','id'], axis = 1))\n",
    "test = np.array(df_test.drop(['id'], axis = 1))\n",
    "\n",
    "xgb_preds = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "\n",
    "lgb_preds = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 3228, shuffle = True)\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.01, \n",
    "    'verbose': -1,\n",
    "    'num_threads': 2,\n",
    "}\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "xgb_w = 8\n",
    "lgb_w = 10 - xgb_w"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "def xgb_f1(y, t, threshold=0.5):\n",
    "    t = t.get_label()\n",
    "    y_bin = (y > threshold).astype(int) # works for both type(y) == <class 'numpy.ndarray'> and type(y) == <class 'pandas.core.series.Series'>\n",
    "    return 'f1',f1_score(t,y_bin)\n",
    "err = 0\n",
    "err2 = 0\n",
    "err3 = 0\n",
    "err4 = 0\n",
    "err5 = 0\n",
    "errLL = 0\n",
    "cutPoint = 0.36\n",
    "for train_index, test_index in kf.split(train):\n",
    "    train_X, valid_X = train[train_index], train[test_index]\n",
    "    train_y, valid_y = target_train[train_index], target_train[test_index]\n",
    "    lgb_train = lgb.Dataset(\n",
    "        train_X, \n",
    "        train_y, \n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        valid_X, \n",
    "        valid_y,\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    lgb_model = lgb.train(\n",
    "        \n",
    "        lgb_params,\n",
    "        lgb_train,\n",
    "        num_boost_round=100000,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=150, \n",
    "        verbose_eval=100, \n",
    "    )\n",
    "    # params configuration also from the1owl's kernel\n",
    "    # https://www.kaggle.com/the1owl/forza-baseline\n",
    "    xgb_params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "    #xgb_params = {'eta': 0.11, 'max_depth': 5, 'subsample': 0.4, 'colsample_bytree': 0.4, 'objective': 'binary:logistic', 'min_child_weight': 15, 'eval_metric': 'auc', 'seed': 99, 'silent': True}\n",
    "\n",
    "    d_train = xgb.DMatrix(train_X, train_y)\n",
    "    d_valid = xgb.DMatrix(valid_X, valid_y)\n",
    "    d_test = xgb.DMatrix(test)\n",
    "    \n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "    model = xgb.train(xgb_params, d_train, 5000,  watchlist, maximize=True, verbose_eval=50, early_stopping_rounds=100)\n",
    "                        \n",
    "    xgb_pred = model.predict(d_test)\n",
    "    lgb_pred = lgb_model.predict(test)\n",
    "    pG = model.predict(d_valid)\n",
    "\n",
    "    errLL += log_loss(valid_y, pG)\n",
    "    p = pG\n",
    "    p[p > cutPoint] = 1\n",
    "    p[p != 1] = 0\n",
    "    err += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err2 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint+0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err3 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.02)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err4 += f1_score(valid_y, p)\n",
    "    p = pG\n",
    "    p[p > (cutPoint-0.01)] = 1\n",
    "    p[p != 1] = 0\n",
    "    err5 += f1_score(valid_y, p)\n",
    "    print(err)\n",
    "    xgb_preds.append(list((((xgb_pred*xgb_w)+(lgb_pred*lgb_w)))/10))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's binary_logloss: 0.350094\tvalid_1's binary_logloss: 0.364902\n",
      "[200]\ttraining's binary_logloss: 0.310633\tvalid_1's binary_logloss: 0.337318\n",
      "[300]\ttraining's binary_logloss: 0.288855\tvalid_1's binary_logloss: 0.325851\n",
      "[400]\ttraining's binary_logloss: 0.272348\tvalid_1's binary_logloss: 0.319852\n",
      "[500]\ttraining's binary_logloss: 0.259674\tvalid_1's binary_logloss: 0.317001\n",
      "[600]\ttraining's binary_logloss: 0.248894\tvalid_1's binary_logloss: 0.315123\n",
      "[700]\ttraining's binary_logloss: 0.23886\tvalid_1's binary_logloss: 0.314268\n",
      "[800]\ttraining's binary_logloss: 0.230239\tvalid_1's binary_logloss: 0.313626\n",
      "[900]\ttraining's binary_logloss: 0.222525\tvalid_1's binary_logloss: 0.313632\n",
      "[1000]\ttraining's binary_logloss: 0.215433\tvalid_1's binary_logloss: 0.313432\n",
      "[1100]\ttraining's binary_logloss: 0.208511\tvalid_1's binary_logloss: 0.313298\n",
      "[1200]\ttraining's binary_logloss: 0.20222\tvalid_1's binary_logloss: 0.313299\n",
      "[1300]\ttraining's binary_logloss: 0.195849\tvalid_1's binary_logloss: 0.313089\n",
      "[1400]\ttraining's binary_logloss: 0.189737\tvalid_1's binary_logloss: 0.31346\n",
      "Early stopping, best iteration is:\n",
      "[1268]\ttraining's binary_logloss: 0.197678\tvalid_1's binary_logloss: 0.312993\n",
      "[17:00:37] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84903\tvalid-auc:0.82441\n",
      "[50]\ttrain-auc:0.87762\tvalid-auc:0.85495\n",
      "[100]\ttrain-auc:0.88528\tvalid-auc:0.86224\n",
      "[150]\ttrain-auc:0.89444\tvalid-auc:0.86938\n",
      "[200]\ttrain-auc:0.90555\tvalid-auc:0.87649\n",
      "[250]\ttrain-auc:0.91409\tvalid-auc:0.88037\n",
      "[300]\ttrain-auc:0.92151\tvalid-auc:0.88313\n",
      "[350]\ttrain-auc:0.92719\tvalid-auc:0.88475\n",
      "[400]\ttrain-auc:0.93260\tvalid-auc:0.88624\n",
      "[450]\ttrain-auc:0.93744\tvalid-auc:0.88687\n",
      "[500]\ttrain-auc:0.94120\tvalid-auc:0.88735\n",
      "[550]\ttrain-auc:0.94518\tvalid-auc:0.88803\n",
      "[600]\ttrain-auc:0.94880\tvalid-auc:0.88832\n",
      "[650]\ttrain-auc:0.95176\tvalid-auc:0.88889\n",
      "[700]\ttrain-auc:0.95477\tvalid-auc:0.88933\n",
      "[750]\ttrain-auc:0.95740\tvalid-auc:0.88992\n",
      "[800]\ttrain-auc:0.95993\tvalid-auc:0.89025\n",
      "[850]\ttrain-auc:0.96212\tvalid-auc:0.89034\n",
      "[900]\ttrain-auc:0.96432\tvalid-auc:0.89043\n",
      "[950]\ttrain-auc:0.96648\tvalid-auc:0.89028\n",
      "[988]\ttrain-auc:0.96778\tvalid-auc:0.89060\n",
      "0.6451612903225806\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's binary_logloss: 0.351018\tvalid_1's binary_logloss: 0.365987\n",
      "[200]\ttraining's binary_logloss: 0.311834\tvalid_1's binary_logloss: 0.335501\n",
      "[300]\ttraining's binary_logloss: 0.289731\tvalid_1's binary_logloss: 0.32421\n",
      "[400]\ttraining's binary_logloss: 0.272778\tvalid_1's binary_logloss: 0.320113\n",
      "[500]\ttraining's binary_logloss: 0.259438\tvalid_1's binary_logloss: 0.317541\n",
      "[600]\ttraining's binary_logloss: 0.249083\tvalid_1's binary_logloss: 0.316447\n",
      "[700]\ttraining's binary_logloss: 0.239425\tvalid_1's binary_logloss: 0.315361\n",
      "[800]\ttraining's binary_logloss: 0.230628\tvalid_1's binary_logloss: 0.314907\n",
      "[900]\ttraining's binary_logloss: 0.222144\tvalid_1's binary_logloss: 0.314508\n",
      "[1000]\ttraining's binary_logloss: 0.214794\tvalid_1's binary_logloss: 0.314006\n",
      "[1100]\ttraining's binary_logloss: 0.207932\tvalid_1's binary_logloss: 0.313682\n",
      "[1200]\ttraining's binary_logloss: 0.201802\tvalid_1's binary_logloss: 0.313379\n",
      "[1300]\ttraining's binary_logloss: 0.196039\tvalid_1's binary_logloss: 0.313104\n",
      "[1400]\ttraining's binary_logloss: 0.190275\tvalid_1's binary_logloss: 0.313032\n",
      "[1500]\ttraining's binary_logloss: 0.184193\tvalid_1's binary_logloss: 0.313016\n",
      "[1600]\ttraining's binary_logloss: 0.178778\tvalid_1's binary_logloss: 0.312916\n",
      "[1700]\ttraining's binary_logloss: 0.173324\tvalid_1's binary_logloss: 0.312601\n",
      "[1800]\ttraining's binary_logloss: 0.168348\tvalid_1's binary_logloss: 0.31255\n",
      "[1900]\ttraining's binary_logloss: 0.163504\tvalid_1's binary_logloss: 0.312503\n",
      "[2000]\ttraining's binary_logloss: 0.15862\tvalid_1's binary_logloss: 0.312529\n",
      "[2100]\ttraining's binary_logloss: 0.153615\tvalid_1's binary_logloss: 0.312665\n",
      "Early stopping, best iteration is:\n",
      "[1983]\ttraining's binary_logloss: 0.15941\tvalid_1's binary_logloss: 0.312471\n",
      "[17:01:45] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84290\tvalid-auc:0.84235\n",
      "[50]\ttrain-auc:0.87733\tvalid-auc:0.86322\n",
      "[100]\ttrain-auc:0.88477\tvalid-auc:0.86974\n",
      "[150]\ttrain-auc:0.89509\tvalid-auc:0.87588\n",
      "[200]\ttrain-auc:0.90602\tvalid-auc:0.88053\n",
      "[250]\ttrain-auc:0.91441\tvalid-auc:0.88329\n",
      "[300]\ttrain-auc:0.92149\tvalid-auc:0.88421\n",
      "[350]\ttrain-auc:0.92712\tvalid-auc:0.88464\n",
      "[400]\ttrain-auc:0.93203\tvalid-auc:0.88541\n",
      "[450]\ttrain-auc:0.93646\tvalid-auc:0.88568\n",
      "[500]\ttrain-auc:0.94029\tvalid-auc:0.88611\n",
      "[550]\ttrain-auc:0.94392\tvalid-auc:0.88655\n",
      "[600]\ttrain-auc:0.94717\tvalid-auc:0.88660\n",
      "[650]\ttrain-auc:0.95050\tvalid-auc:0.88635\n",
      "[694]\ttrain-auc:0.95316\tvalid-auc:0.88633\n",
      "1.3155010515714327\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's binary_logloss: 0.351445\tvalid_1's binary_logloss: 0.359563\n",
      "[200]\ttraining's binary_logloss: 0.311033\tvalid_1's binary_logloss: 0.333745\n",
      "[300]\ttraining's binary_logloss: 0.288802\tvalid_1's binary_logloss: 0.325754\n",
      "[400]\ttraining's binary_logloss: 0.271451\tvalid_1's binary_logloss: 0.321681\n",
      "[500]\ttraining's binary_logloss: 0.25866\tvalid_1's binary_logloss: 0.319479\n",
      "[600]\ttraining's binary_logloss: 0.247154\tvalid_1's binary_logloss: 0.318021\n",
      "[700]\ttraining's binary_logloss: 0.237191\tvalid_1's binary_logloss: 0.317665\n",
      "[800]\ttraining's binary_logloss: 0.228506\tvalid_1's binary_logloss: 0.317438\n",
      "[900]\ttraining's binary_logloss: 0.220725\tvalid_1's binary_logloss: 0.317284\n",
      "[1000]\ttraining's binary_logloss: 0.21381\tvalid_1's binary_logloss: 0.317021\n",
      "[1100]\ttraining's binary_logloss: 0.20694\tvalid_1's binary_logloss: 0.317228\n",
      "Early stopping, best iteration is:\n",
      "[996]\ttraining's binary_logloss: 0.214004\tvalid_1's binary_logloss: 0.317\n",
      "[17:02:14] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84511\tvalid-auc:0.82217\n",
      "[50]\ttrain-auc:0.87908\tvalid-auc:0.85960\n",
      "[100]\ttrain-auc:0.88705\tvalid-auc:0.86489\n",
      "[150]\ttrain-auc:0.89773\tvalid-auc:0.86957\n",
      "[200]\ttrain-auc:0.90785\tvalid-auc:0.87337\n",
      "[250]\ttrain-auc:0.91648\tvalid-auc:0.87654\n",
      "[300]\ttrain-auc:0.92313\tvalid-auc:0.87842\n",
      "[350]\ttrain-auc:0.92930\tvalid-auc:0.87918\n",
      "[400]\ttrain-auc:0.93399\tvalid-auc:0.88035\n",
      "[450]\ttrain-auc:0.93848\tvalid-auc:0.88159\n",
      "[500]\ttrain-auc:0.94240\tvalid-auc:0.88220\n",
      "[550]\ttrain-auc:0.94593\tvalid-auc:0.88278\n",
      "[600]\ttrain-auc:0.94920\tvalid-auc:0.88316\n",
      "[650]\ttrain-auc:0.95245\tvalid-auc:0.88379\n",
      "[700]\ttrain-auc:0.95482\tvalid-auc:0.88411\n",
      "[750]\ttrain-auc:0.95770\tvalid-auc:0.88438\n",
      "[800]\ttrain-auc:0.96007\tvalid-auc:0.88487\n",
      "[850]\ttrain-auc:0.96248\tvalid-auc:0.88471\n",
      "[900]\ttrain-auc:0.96477\tvalid-auc:0.88486\n",
      "[906]\ttrain-auc:0.96494\tvalid-auc:0.88483\n",
      "1.9737744328663966\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's binary_logloss: 0.351764\tvalid_1's binary_logloss: 0.357994\n",
      "[200]\ttraining's binary_logloss: 0.312403\tvalid_1's binary_logloss: 0.328073\n",
      "[300]\ttraining's binary_logloss: 0.290431\tvalid_1's binary_logloss: 0.318105\n",
      "[400]\ttraining's binary_logloss: 0.273145\tvalid_1's binary_logloss: 0.312553\n",
      "[500]\ttraining's binary_logloss: 0.259956\tvalid_1's binary_logloss: 0.309547\n",
      "[600]\ttraining's binary_logloss: 0.249752\tvalid_1's binary_logloss: 0.307849\n",
      "[700]\ttraining's binary_logloss: 0.241178\tvalid_1's binary_logloss: 0.306924\n",
      "[800]\ttraining's binary_logloss: 0.233461\tvalid_1's binary_logloss: 0.306643\n",
      "[900]\ttraining's binary_logloss: 0.225996\tvalid_1's binary_logloss: 0.30683\n",
      "Early stopping, best iteration is:\n",
      "[782]\ttraining's binary_logloss: 0.234796\tvalid_1's binary_logloss: 0.306524\n",
      "[17:02:43] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84547\tvalid-auc:0.84242\n",
      "[50]\ttrain-auc:0.87435\tvalid-auc:0.86499\n",
      "[100]\ttrain-auc:0.88440\tvalid-auc:0.87183\n",
      "[150]\ttrain-auc:0.89480\tvalid-auc:0.87774\n",
      "[200]\ttrain-auc:0.90547\tvalid-auc:0.88303\n",
      "[250]\ttrain-auc:0.91375\tvalid-auc:0.88494\n",
      "[300]\ttrain-auc:0.92058\tvalid-auc:0.88681\n",
      "[350]\ttrain-auc:0.92625\tvalid-auc:0.88787\n",
      "[400]\ttrain-auc:0.93135\tvalid-auc:0.88885\n",
      "[450]\ttrain-auc:0.93571\tvalid-auc:0.88970\n",
      "[500]\ttrain-auc:0.93969\tvalid-auc:0.88974\n",
      "[550]\ttrain-auc:0.94357\tvalid-auc:0.89005\n",
      "[600]\ttrain-auc:0.94684\tvalid-auc:0.89015\n",
      "[650]\ttrain-auc:0.94983\tvalid-auc:0.89044\n",
      "[700]\ttrain-auc:0.95240\tvalid-auc:0.89061\n",
      "[750]\ttrain-auc:0.95506\tvalid-auc:0.89075\n",
      "[800]\ttrain-auc:0.95756\tvalid-auc:0.89071\n",
      "[814]\ttrain-auc:0.95830\tvalid-auc:0.89070\n",
      "2.657597962278161\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "[100]\ttraining's binary_logloss: 0.351626\tvalid_1's binary_logloss: 0.363142\n",
      "[200]\ttraining's binary_logloss: 0.311784\tvalid_1's binary_logloss: 0.330556\n",
      "[300]\ttraining's binary_logloss: 0.289837\tvalid_1's binary_logloss: 0.317397\n",
      "[400]\ttraining's binary_logloss: 0.273494\tvalid_1's binary_logloss: 0.311473\n",
      "[500]\ttraining's binary_logloss: 0.261485\tvalid_1's binary_logloss: 0.308204\n",
      "[600]\ttraining's binary_logloss: 0.250219\tvalid_1's binary_logloss: 0.306671\n",
      "[700]\ttraining's binary_logloss: 0.24085\tvalid_1's binary_logloss: 0.305688\n",
      "[800]\ttraining's binary_logloss: 0.232215\tvalid_1's binary_logloss: 0.305348\n",
      "[900]\ttraining's binary_logloss: 0.22409\tvalid_1's binary_logloss: 0.305334\n",
      "[1000]\ttraining's binary_logloss: 0.216853\tvalid_1's binary_logloss: 0.305113\n",
      "[1100]\ttraining's binary_logloss: 0.210112\tvalid_1's binary_logloss: 0.305076\n",
      "Early stopping, best iteration is:\n",
      "[1024]\ttraining's binary_logloss: 0.215195\tvalid_1's binary_logloss: 0.304998\n",
      "[17:03:10] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.84037\tvalid-auc:0.85112\n",
      "[50]\ttrain-auc:0.87314\tvalid-auc:0.87982\n",
      "[100]\ttrain-auc:0.88142\tvalid-auc:0.88549\n",
      "[150]\ttrain-auc:0.89253\tvalid-auc:0.89155\n",
      "[200]\ttrain-auc:0.90292\tvalid-auc:0.89499\n",
      "[250]\ttrain-auc:0.91157\tvalid-auc:0.89719\n",
      "[300]\ttrain-auc:0.91840\tvalid-auc:0.89817\n",
      "[350]\ttrain-auc:0.92418\tvalid-auc:0.89952\n",
      "[400]\ttrain-auc:0.92956\tvalid-auc:0.90010\n",
      "[450]\ttrain-auc:0.93429\tvalid-auc:0.90048\n",
      "[500]\ttrain-auc:0.93882\tvalid-auc:0.90065\n",
      "[550]\ttrain-auc:0.94281\tvalid-auc:0.90086\n",
      "[600]\ttrain-auc:0.94640\tvalid-auc:0.90093\n",
      "[623]\ttrain-auc:0.94796\tvalid-auc:0.90074\n",
      "3.356559899994424\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "xgb_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.8809537 , 0.5762347 , 0.22421467, ..., 0.5541503 , 0.4149281 ,\n",
       "       0.14109486], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "print(err/5) #print(err/4) #6711266\n",
    "print(err2/5) #print(err/4) #6711266\n",
    "print(err3/5) #print(err/4) #6711266\n",
    "print(err4/5) #print(err/4) #6711266\n",
    "print(err5/5) #print(err/4) #6711266\n",
    "print(errLL/5) #print(err/4) #6711266"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6713119799988848\n",
      "0.6713119799988848\n",
      "0.6713119799988848\n",
      "0.6713119799988848\n",
      "0.6713119799988848\n",
      "0.307419797130156\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "preds=[]\n",
    "for i in range(len(xgb_preds[0])):\n",
    "    sum=0\n",
    "    for j in range(K):\n",
    "        sum+= xgb_preds[j][i]\n",
    "    preds.append(sum / K)\n",
    "\n",
    "output = pd.DataFrame({'id': id_test, 'predicted': preds})\n",
    "output['predicted'][output['predicted'] > cutPoint] = 1\n",
    "output['predicted'][output['predicted'] != 1] = 0\n",
    "output['predicted'] = output['predicted'].astype(int)\n",
    "output.to_csv(\"../data/output/{}-foldCV_avg_sub_dummy_person_cutpoint{}_error{}_logloss{}_stackingXGBLGB_w{}.csv\".format(K,cutPoint, err/5, errLL/5, xgb_w), index=False)   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-49-f6a6dd67e39b>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] > cutPoint] = 1\n",
      "<ipython-input-49-f6a6dd67e39b>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output['predicted'][output['predicted'] != 1] = 0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.8042323565804277,\n",
       " 0.41038777477949206,\n",
       " -1.0522606733771749,\n",
       " -0.25138078858893376,\n",
       " -0.4567954260273539,\n",
       " -2.2922542963187715,\n",
       " 0.33318610444021457,\n",
       " -3.3716836687302,\n",
       " 2.552722908285543,\n",
       " -3.4688423788692537,\n",
       " -0.4455704650340236,\n",
       " 1.2797088465732864,\n",
       " 0.5514737085645274,\n",
       " -1.2745198788317063,\n",
       " -0.6736042820644619,\n",
       " -4.10655505313605,\n",
       " -4.538364533304628,\n",
       " -2.5795617502397694,\n",
       " 2.6183872462242244,\n",
       " -0.2533613574804656,\n",
       " -3.0643439596828848,\n",
       " -1.6787980568611176,\n",
       " -1.8698275895147318,\n",
       " 2.3225378825904186,\n",
       " -0.7865530631017743,\n",
       " -2.578908246508007,\n",
       " -1.6735292449659993,\n",
       " -1.8892818975977228,\n",
       " 0.6465017610200811,\n",
       " 0.9993018340232499,\n",
       " 0.3842278990387601,\n",
       " -3.5969435918457213,\n",
       " -2.4293568463253603,\n",
       " 0.9594646578806941,\n",
       " -0.31569421708026846,\n",
       " 1.9429804954573477,\n",
       " -0.5364576101594073,\n",
       " -1.5985411919160997,\n",
       " -0.0631660058926542,\n",
       " 1.0613999322658283,\n",
       " 1.3967211891082578,\n",
       " -2.4080408322920044,\n",
       " -2.1244810245999863,\n",
       " -3.6158205747693897,\n",
       " 0.7666878120819897,\n",
       " -1.0635515485839295,\n",
       " -3.1024079742441066,\n",
       " 1.4662191179641486,\n",
       " 2.169485553444003,\n",
       " -0.2095113007203667,\n",
       " -2.9063748837533283,\n",
       " -3.6861059736522996,\n",
       " 0.6882446879082776,\n",
       " -3.8911499205787643,\n",
       " 1.5603054107027168,\n",
       " -2.0201423747574587,\n",
       " 2.4733750350057973,\n",
       " -2.4101412893378735,\n",
       " -0.05452541081641134,\n",
       " 2.2522183495999775,\n",
       " -1.5802573897123104,\n",
       " 0.8846580735154843,\n",
       " -2.3316745841148516,\n",
       " -1.4664812087426082,\n",
       " -2.7380823643412717,\n",
       " 1.5830052874484877,\n",
       " 0.7925569649514875,\n",
       " -0.41599322258217575,\n",
       " -0.03496755386585078,\n",
       " -1.8502860604164906,\n",
       " 0.5769111700059588,\n",
       " -2.666609377856509,\n",
       " -2.6816473225336797,\n",
       " 0.135091740371003,\n",
       " -1.2086405752057459,\n",
       " -2.030071750353335,\n",
       " -0.8979254223000442,\n",
       " 0.5286437071858853,\n",
       " -1.1186321244861637,\n",
       " 0.4847858511329136,\n",
       " -0.4451494781139206,\n",
       " 1.2511157417383552,\n",
       " 0.40076977369036015,\n",
       " -1.1664563987883074,\n",
       " 0.30052116208418556,\n",
       " -1.9581628168291314,\n",
       " 0.8399075758983134,\n",
       " 0.27544640983868673,\n",
       " 2.600739017733019,\n",
       " 0.9197423325724581,\n",
       " -1.4192964793607035,\n",
       " -4.430921726816999,\n",
       " -2.0086125865193667,\n",
       " 1.0229567867606895,\n",
       " 0.4200358594382593,\n",
       " 0.6261939840371594,\n",
       " 0.17773777784777706,\n",
       " -2.978681661777967,\n",
       " 0.6692084691647626,\n",
       " -0.5904596454077616,\n",
       " 2.2824460283285677,\n",
       " -2.2685209809309974,\n",
       " -0.19433988157836607,\n",
       " -0.6558658219792568,\n",
       " 0.3862075911114019,\n",
       " -1.8048668035415087,\n",
       " 1.509162882447279,\n",
       " -2.288696909339841,\n",
       " -3.6169628614112086,\n",
       " 1.341256155125724,\n",
       " -0.9698876236396657,\n",
       " -3.9965838279685557,\n",
       " -0.9988761804256935,\n",
       " -2.033812281828895,\n",
       " -1.2958245185584294,\n",
       " -0.9051007790497358,\n",
       " 0.8356313705987336,\n",
       " 2.5516811302558677,\n",
       " 2.2242048716853424,\n",
       " 0.4507581056766162,\n",
       " -0.4704448137099158,\n",
       " -3.943395024662327,\n",
       " 0.41975660023680783,\n",
       " -2.558115820651439,\n",
       " -0.49561834600797533,\n",
       " 0.03744692427429983,\n",
       " -2.5795869596636325,\n",
       " -1.6372448116609113,\n",
       " -3.2863620251154986,\n",
       " -3.2936885658256174,\n",
       " 0.23355180727058858,\n",
       " 0.8814997473852808,\n",
       " -0.6010964136129765,\n",
       " -2.4483451254648143,\n",
       " -1.6798455623710367,\n",
       " -0.3550379730842886,\n",
       " 0.8007388198519794,\n",
       " 2.0515821007145396,\n",
       " -2.9303814979322524,\n",
       " -3.1637144824432526,\n",
       " -2.74831051082121,\n",
       " -1.9274850708429867,\n",
       " -3.0819278429002295,\n",
       " -4.340039643739659,\n",
       " 1.7754552371018477,\n",
       " 0.118502895645006,\n",
       " 2.827317131988815,\n",
       " -1.9146830140271462,\n",
       " 0.7294184067428594,\n",
       " -2.045065907460347,\n",
       " 2.9124860381610267,\n",
       " -2.4109996712177137,\n",
       " 2.6574496701574324,\n",
       " -2.250496765504522,\n",
       " -0.26275915704697367,\n",
       " 2.5685129265357807,\n",
       " 2.8866157150371365,\n",
       " 1.7866646394641812,\n",
       " -0.8348799677536922,\n",
       " -0.7353343884367549,\n",
       " -0.326228438865065,\n",
       " 0.6221826437611127,\n",
       " -1.1367138413593616,\n",
       " 3.31489005799599,\n",
       " 2.8351341105722105,\n",
       " -0.20869324923198235,\n",
       " -3.121240836522735,\n",
       " -3.6923303609527722,\n",
       " -1.5737042238064967,\n",
       " -3.842244927774092,\n",
       " 0.2868060193618208,\n",
       " -3.1355535160409054,\n",
       " -0.8160595618549898,\n",
       " -1.132527981435444,\n",
       " -0.6505639198428079,\n",
       " -2.590295367791417,\n",
       " -2.7128083560655667,\n",
       " -0.04461727694211119,\n",
       " 2.2132996770619986,\n",
       " -3.583261304841403,\n",
       " 1.0687951282914674,\n",
       " -2.9001385615926574,\n",
       " 0.386490799920128,\n",
       " 1.5566217345394109,\n",
       " -2.825686425348009,\n",
       " 0.8490148513321134,\n",
       " 2.090952344887742,\n",
       " -3.4061988714720153,\n",
       " -1.1789521468931776,\n",
       " 1.6896184521910205,\n",
       " -0.15145241198308562,\n",
       " -3.7803154274573045,\n",
       " -1.7591559389739977,\n",
       " -0.2857910625948295,\n",
       " 2.3342723894645387,\n",
       " -3.5401266307113937,\n",
       " -0.6794027853783893,\n",
       " -3.146662194668047,\n",
       " -3.098196739060846,\n",
       " -4.034303069668506,\n",
       " -0.3691984618169143,\n",
       " -1.9208588416135732,\n",
       " 1.7556507724755002,\n",
       " -0.3426645378602722,\n",
       " -1.0005912174759377,\n",
       " -0.2877815891508334,\n",
       " -2.4452013388882596,\n",
       " 0.8967740411188541,\n",
       " -3.322320783127045,\n",
       " -0.6903142221303683,\n",
       " 1.6553929537318333,\n",
       " -3.8765795229458844,\n",
       " 0.28079433772011647,\n",
       " -2.1352075449023262,\n",
       " -3.1055036347796294,\n",
       " -1.8400663061315405,\n",
       " -2.8481952392407184,\n",
       " -3.7029834799554693,\n",
       " 0.5460112024499526,\n",
       " -1.0989287316791283,\n",
       " -3.4761601096358454,\n",
       " 1.986935829294015,\n",
       " 0.7274575375991417,\n",
       " -1.3449777316921847,\n",
       " 1.2379702561251285,\n",
       " 0.5036507971234319,\n",
       " -1.2862352515029785,\n",
       " -1.2388090132029101,\n",
       " 0.659604783428534,\n",
       " 2.765769040756249,\n",
       " -1.044617058718225,\n",
       " -3.1217579666878583,\n",
       " 1.0938444515397308,\n",
       " -1.5023456624019547,\n",
       " -2.3231528883114665,\n",
       " -0.2950970881884323,\n",
       " -1.4685156242487758,\n",
       " 1.820578277712895,\n",
       " 0.0848121014822661,\n",
       " -3.602146261008733,\n",
       " -2.5081278973145213,\n",
       " -1.5058624827957785,\n",
       " -0.9460127727788556,\n",
       " -4.726222886786897,\n",
       " -1.8194590868305422,\n",
       " -1.072965311447214,\n",
       " -0.20304934459054125,\n",
       " -4.181637617549025,\n",
       " 2.528457383523592,\n",
       " -3.062495417278554,\n",
       " -0.7814209411863471,\n",
       " -1.1257756047903071,\n",
       " -0.9275880302370638,\n",
       " -2.60029414375935,\n",
       " -2.615658375880585,\n",
       " -0.8118316139819978,\n",
       " 0.15833022403802616,\n",
       " -0.4506840073402431,\n",
       " 0.7423450244489572,\n",
       " -0.0634609637352231,\n",
       " -0.7551943597085252,\n",
       " -1.3364368279747727,\n",
       " 1.9865263956476291,\n",
       " 1.962646685779136,\n",
       " 2.9299765302078287,\n",
       " -2.780470124886631,\n",
       " -3.5328245172407646,\n",
       " 0.3096963485156512,\n",
       " -2.665673532607553,\n",
       " -0.06699305342711581,\n",
       " -4.121267387912586,\n",
       " -0.5194909906223121,\n",
       " -0.30162525679870933,\n",
       " 0.08533061440495734,\n",
       " 0.9698624002043983,\n",
       " 2.892004058852791,\n",
       " -0.09884845874198574,\n",
       " -1.158463308196725,\n",
       " 1.7146792903574728,\n",
       " -1.944632027731084,\n",
       " -3.3547725679013793,\n",
       " 0.34868118564378303,\n",
       " -2.1436638693246466,\n",
       " -3.1983892221450856,\n",
       " -4.262516660046923,\n",
       " -2.1080375305472274,\n",
       " -1.124003564352894,\n",
       " 1.2188028409634004,\n",
       " 0.0629536345037762,\n",
       " -3.822997975562638,\n",
       " 2.4680008294492968,\n",
       " 0.34957036609125913,\n",
       " -2.700212154345814,\n",
       " 0.1146764433073846,\n",
       " -2.7334203076025396,\n",
       " -1.8142882366515738,\n",
       " -2.8995667811249666,\n",
       " -1.673270081201273,\n",
       " -4.112149011465778,\n",
       " -1.715123471139168,\n",
       " -3.662606240783174,\n",
       " -1.0571777929103399,\n",
       " 0.25323228135303727,\n",
       " -0.15450240873691498,\n",
       " -0.8935648294083464,\n",
       " -3.9609043876441783,\n",
       " -1.5157856775404777,\n",
       " -0.8910981925096401,\n",
       " -1.0353827405252891,\n",
       " -3.2080012903254067,\n",
       " 1.5695892931579862,\n",
       " -2.500567357944962,\n",
       " 0.2964938602190631,\n",
       " -4.319357467602279,\n",
       " 2.669267804783058,\n",
       " 0.3445542431275452,\n",
       " -0.05537626013107422,\n",
       " -3.000502224801136,\n",
       " 0.40871940840309245,\n",
       " -0.13932418032686583,\n",
       " 0.5988105002183085,\n",
       " -0.842359870477905,\n",
       " -4.103935062780243,\n",
       " -3.075061426599398,\n",
       " 2.581920013496878,\n",
       " -0.5478575981088298,\n",
       " -0.13516495236807752,\n",
       " 2.1958351336436643,\n",
       " -2.5128032646552385,\n",
       " -3.3521111023086876,\n",
       " -0.20275806788221612,\n",
       " 1.966090779565974,\n",
       " 1.9995295739554737,\n",
       " 0.295890958709368,\n",
       " -1.9327053206326454,\n",
       " -0.0411603567178247,\n",
       " 2.1747717899279224,\n",
       " -4.436826786845392,\n",
       " -3.0198182458205998,\n",
       " -0.308410520612755,\n",
       " -2.192980025625907,\n",
       " -3.009028524180271,\n",
       " 1.8916665241406343,\n",
       " -0.08688148490914022,\n",
       " -0.8235980143393086,\n",
       " 2.4061139488265346,\n",
       " -1.0201666327272938,\n",
       " 1.1647224293812244,\n",
       " 0.6878096848633878,\n",
       " -1.8177219073962223,\n",
       " -0.5793481694158248,\n",
       " -0.1585571453567137,\n",
       " -0.374866188578635,\n",
       " -1.7058213788118661,\n",
       " -0.8720436095061574,\n",
       " -2.4829791840181605,\n",
       " 0.9115269956726154,\n",
       " -2.2557903200250786,\n",
       " 0.35976555021228374,\n",
       " -1.527664442859817,\n",
       " 0.06762301171793914,\n",
       " -4.197078079054512,\n",
       " -0.966149298243107,\n",
       " -1.2815341934488977,\n",
       " 0.5482072844050794,\n",
       " 0.36696706728068207,\n",
       " 0.6324755120950251,\n",
       " -2.7505933703079357,\n",
       " -0.6213149423233925,\n",
       " -2.9791135668652515,\n",
       " -1.924428937912807,\n",
       " -0.38847712961801467,\n",
       " -1.213179543795352,\n",
       " -3.499236347791995,\n",
       " 0.665406756038325,\n",
       " -2.940957837108685,\n",
       " -1.7774057836111286,\n",
       " -3.9130301906677594,\n",
       " 2.485734585237712,\n",
       " 2.1526066450488046,\n",
       " -2.6632637020904277,\n",
       " -1.7262537800206341,\n",
       " 0.6094615777871388,\n",
       " -1.4253575024290543,\n",
       " 1.5814005836983958,\n",
       " -1.9351640257911833,\n",
       " -1.8376006774839468,\n",
       " -3.334662716034379,\n",
       " -2.363852223065097,\n",
       " 0.5915143179932839,\n",
       " -2.5601867110850653,\n",
       " 0.14950418999157383,\n",
       " -0.8518394824120572,\n",
       " -0.5580417424461821,\n",
       " 0.412763457448861,\n",
       " -1.0263560428279848,\n",
       " -2.0863802177172546,\n",
       " -0.48106364073326857,\n",
       " 1.4081647522598264,\n",
       " -1.002171475871879,\n",
       " 2.816950473891722,\n",
       " 1.2536276555870862,\n",
       " 0.6200951690854442,\n",
       " 1.194170576212396,\n",
       " 1.2494970677492307,\n",
       " -1.5028780164417797,\n",
       " 1.7643080874937958,\n",
       " 2.22536802659581,\n",
       " -1.7938641687738013,\n",
       " -1.5814538427063254,\n",
       " -0.9802721712017064,\n",
       " -1.7271129738556534,\n",
       " -4.598363570262246,\n",
       " -3.675743380275353,\n",
       " -2.7942866274798592,\n",
       " 2.7710968784124326,\n",
       " -4.0073837023895855,\n",
       " -0.6540245321666583,\n",
       " -0.6070484768423065,\n",
       " 1.3017114116516864,\n",
       " -3.9838781582652687,\n",
       " 0.052360270051270585,\n",
       " -0.21127484253328915,\n",
       " -1.5689608107722746,\n",
       " -1.3489599539987787,\n",
       " -1.9589740807289118,\n",
       " -0.4496201698227355,\n",
       " 0.3229095623879426,\n",
       " -1.9625980510094378,\n",
       " -0.4358305188212224,\n",
       " 0.8270821047242969,\n",
       " -1.9702057356923646,\n",
       " -1.1928781127196433,\n",
       " 0.8170474440772791,\n",
       " 0.5055246535628533,\n",
       " -3.9562033187437984,\n",
       " -0.39810251090208626,\n",
       " -0.237100403587714,\n",
       " 0.7747702651775846,\n",
       " -2.3720261093099,\n",
       " -3.7781945628113434,\n",
       " 2.3878569280145188,\n",
       " -0.3395559526915791,\n",
       " -3.925042845657413,\n",
       " -0.20533974696133997,\n",
       " 0.9271803275868011,\n",
       " 0.16670243049538422,\n",
       " -3.413629175706434,\n",
       " -1.1835434302284562,\n",
       " 2.1347239252292765,\n",
       " 2.782321672689277,\n",
       " 3.1675555102528996,\n",
       " 1.3752296879513057,\n",
       " -1.7232168871944906,\n",
       " -1.172042520573814,\n",
       " -2.183770876920131,\n",
       " 0.710019585706976,\n",
       " 1.4014052920966535,\n",
       " 2.189614639880964,\n",
       " -3.966731764342009,\n",
       " -2.3718608750279144,\n",
       " -1.392716884603052,\n",
       " -1.4675748107841642,\n",
       " -0.3382984762253574,\n",
       " -1.0161266470439196,\n",
       " 0.5040966083863216,\n",
       " -1.0475251314854843,\n",
       " 1.2083813301582116,\n",
       " 1.5557022611769675,\n",
       " -0.9450731400305269,\n",
       " -3.6120818258987377,\n",
       " 2.2777525106809398,\n",
       " -1.658930232547278,\n",
       " -0.6309896141909114,\n",
       " 0.17053017211018984,\n",
       " 2.6238823308488306,\n",
       " 0.5644063225355577,\n",
       " 0.7464978768526451,\n",
       " 1.509640396939979,\n",
       " -1.9171578300855443,\n",
       " -3.173921561622289,\n",
       " -0.6471758562324006,\n",
       " -3.256269935780588,\n",
       " -2.686142449479406,\n",
       " -1.3217777982751202,\n",
       " 0.2030165066701463,\n",
       " 2.412831359838985,\n",
       " -4.085970526623109,\n",
       " -0.11599239862343369,\n",
       " -2.546686572766945,\n",
       " 0.6144142707869981,\n",
       " 1.469059533860222,\n",
       " -0.08278329016083244,\n",
       " -1.3577026042110223,\n",
       " -1.0395713076891755,\n",
       " -2.2663347990361564,\n",
       " -3.1081452130566083,\n",
       " -3.147850056203874,\n",
       " -1.8946974016643345,\n",
       " 2.6265165486373796,\n",
       " -0.2747178936317699,\n",
       " -3.7091409815482534,\n",
       " 2.4787086307514605,\n",
       " -0.5370872040728887,\n",
       " 1.48941321410762,\n",
       " 2.310229332087947,\n",
       " -3.8525998952172955,\n",
       " -2.9044164043342926,\n",
       " 1.6519812269415861,\n",
       " -2.1724706938613947,\n",
       " 1.0537932542424162,\n",
       " 0.6511080584729025,\n",
       " -4.031849503977166,\n",
       " 0.7896166624949494,\n",
       " 2.692793081928334,\n",
       " -1.27517067031195,\n",
       " -1.3734903185911158,\n",
       " -1.743461246300966,\n",
       " -2.194972405643037,\n",
       " -2.302790693793925,\n",
       " -1.1606479526276823,\n",
       " -1.944974185999135,\n",
       " -1.336796118952181,\n",
       " -2.1678493201044335,\n",
       " -0.3178059909559125,\n",
       " 1.7643268546515831,\n",
       " -2.2551608821869986,\n",
       " -1.3135967260380603,\n",
       " -0.6919613593008727,\n",
       " -0.8360651865585045,\n",
       " -2.6685959859807253,\n",
       " 0.10408034476015168,\n",
       " -4.227146612293003,\n",
       " 1.4043097925203472,\n",
       " 0.9456336476086198,\n",
       " -2.9529967670460664,\n",
       " -0.6636412891773075,\n",
       " -4.58142935840585,\n",
       " -2.912247519919976,\n",
       " 2.4266907017612773,\n",
       " -0.09665404630406552,\n",
       " -0.5207019239991095,\n",
       " 2.005765902957603,\n",
       " 0.8425000818785744,\n",
       " -2.004588427996507,\n",
       " -1.700578919357638,\n",
       " -1.4977059188510775,\n",
       " -0.46287462088602427,\n",
       " -1.3159567434938773,\n",
       " -1.3557443757490364,\n",
       " 0.02309739662596712,\n",
       " 2.4681286648124092,\n",
       " -0.12565876714816485,\n",
       " 2.457309768718475,\n",
       " -3.046761581205002,\n",
       " -1.7447132413201512,\n",
       " -2.882311776761481,\n",
       " -2.0196373083990538,\n",
       " 1.7671290376420992,\n",
       " 0.3241668910811445,\n",
       " 2.8504125862372782,\n",
       " -3.5961146905331987,\n",
       " -2.851950923872793,\n",
       " 1.8915558070792564,\n",
       " 0.9781370962624463,\n",
       " 2.07208162956485,\n",
       " -3.336988417804254,\n",
       " 2.480776081524074,\n",
       " -1.4591363530722838,\n",
       " -1.955407268501738,\n",
       " -0.17432301833551486,\n",
       " -0.4064457489130942,\n",
       " 2.0784961953875696,\n",
       " -1.0831195616939544,\n",
       " -0.5833198101785617,\n",
       " -3.3365292125482555,\n",
       " -3.6480670387935445,\n",
       " 0.638267014850405,\n",
       " -1.6413116470846614,\n",
       " 0.4622587804509495,\n",
       " -0.5690134425997886,\n",
       " -2.867796720671955,\n",
       " -3.3609128868955302,\n",
       " 2.1220615226488646,\n",
       " -1.6685051661506438,\n",
       " -2.3260697403960013,\n",
       " -0.08789372774679287,\n",
       " -0.7520432768478539,\n",
       " 2.1669782379460356,\n",
       " -0.5937991933249833,\n",
       " 0.10996856061951402,\n",
       " -1.5853067776349306,\n",
       " 0.36164540356145836,\n",
       " -1.529336102220585,\n",
       " 0.3060467433158079,\n",
       " -0.5289759208721472,\n",
       " -0.9471409839224174,\n",
       " 0.10720488415326161,\n",
       " -2.722398631649683,\n",
       " 1.9228822793845133,\n",
       " 2.5836756831205845,\n",
       " -1.862701329542191,\n",
       " 0.7504456331450523,\n",
       " -0.0015028935655333707,\n",
       " 1.668435967527391,\n",
       " -1.0175437279370727,\n",
       " 2.305060407080194,\n",
       " -1.3475042318461017,\n",
       " -1.1866877599950774,\n",
       " -1.0651485694684184,\n",
       " 2.0637579453481996,\n",
       " -0.29697889473680167,\n",
       " -0.9024995785552037,\n",
       " -1.8006641371618897,\n",
       " -3.2175849088824107,\n",
       " -1.8483036442609169,\n",
       " -2.978700564315751,\n",
       " -1.9293051775655303,\n",
       " -4.12877985378429,\n",
       " 1.2952874014806173,\n",
       " -1.8123406543188902,\n",
       " -0.18531827583975827,\n",
       " 0.30378013396093106,\n",
       " -2.987208859977666,\n",
       " -3.906177471959796,\n",
       " 0.4987574210575457,\n",
       " -3.192834319544339,\n",
       " -1.2943817242181392,\n",
       " -2.421479500793948,\n",
       " 2.155047641462378,\n",
       " -2.415491816379977,\n",
       " -0.8171940165228901,\n",
       " -4.289881637700097,\n",
       " 1.2973071014809243,\n",
       " -2.1862210253338037,\n",
       " 1.929148821377084,\n",
       " -0.8703763372936886,\n",
       " -0.6989241890251405,\n",
       " -0.6149476469462914,\n",
       " -2.1934053913509306,\n",
       " -1.6091828089172888,\n",
       " -2.679233305153209,\n",
       " 0.47739569936914333,\n",
       " -2.929592024738917,\n",
       " -1.7010638649878391,\n",
       " -3.4302266344958987,\n",
       " 0.5491741930594098,\n",
       " -0.0943539693898656,\n",
       " -1.5396326890004506,\n",
       " -1.8971193327640996,\n",
       " -0.335259636448867,\n",
       " -2.4876893347690827,\n",
       " -3.45873640744765,\n",
       " 0.9049462712629233,\n",
       " 2.455088484020945,\n",
       " -0.24721489176834271,\n",
       " 0.805915278065178,\n",
       " -2.6643533754119715,\n",
       " -1.9399903020496587,\n",
       " -3.4159356311713283,\n",
       " -3.4908849191186633,\n",
       " -1.0223772554308252,\n",
       " -0.3046429903789002,\n",
       " -2.7130222220520905,\n",
       " -1.7564026433597235,\n",
       " -1.6498989305038543,\n",
       " -2.6104157235024,\n",
       " -1.6598893112202688,\n",
       " -1.4640795459987355,\n",
       " -3.2497780952058037,\n",
       " -3.3164616789849988,\n",
       " -1.4067437924641504,\n",
       " 2.7345525722045396,\n",
       " -1.5658130443589287,\n",
       " 2.1961736479195606,\n",
       " -2.0790442141299916,\n",
       " 1.0388783640433128,\n",
       " -1.7855546706920937,\n",
       " -0.003670529292613578,\n",
       " -0.30569405333585453,\n",
       " -3.3201414122619837,\n",
       " -1.8879282514482785,\n",
       " 0.8978736746514853,\n",
       " -1.2947636888176695,\n",
       " 1.7458646381962801,\n",
       " -1.6317256278529513,\n",
       " -2.621966110309734,\n",
       " -2.5435517188921275,\n",
       " -0.8598444971979735,\n",
       " -3.077182569327436,\n",
       " 0.16905598675734573,\n",
       " -1.3967096805322534,\n",
       " 0.36650271407100465,\n",
       " 0.20671177005708657,\n",
       " -3.6338838034711207,\n",
       " -2.1313019499399593,\n",
       " 2.477804652828009,\n",
       " -0.06800902680505042,\n",
       " 0.8046382248543846,\n",
       " -1.725163654127228,\n",
       " -2.0563267389110087,\n",
       " -0.5735654085373115,\n",
       " -1.6304731522099758,\n",
       " -1.4370967887054742,\n",
       " -0.2635162493144355,\n",
       " -1.1222913192117416,\n",
       " -1.7563407456219253,\n",
       " -0.7261041665098277,\n",
       " 2.7816524037928656,\n",
       " 1.0484760721876314,\n",
       " -2.037298765392327,\n",
       " 0.1609969354888237,\n",
       " -2.8198304226601967,\n",
       " 0.18330002703037204,\n",
       " -1.2895842885134416,\n",
       " -2.204652212226537,\n",
       " 1.7119702542364414,\n",
       " 0.963105599637886,\n",
       " -2.3010184046916207,\n",
       " 2.7115612164636205,\n",
       " -1.7502073614093678,\n",
       " -0.7909611249200714,\n",
       " -0.7759852879326433,\n",
       " 0.1147729334276979,\n",
       " -2.9541748215819044,\n",
       " -1.7585520218744062,\n",
       " -0.7972082323621912,\n",
       " 2.245141752718864,\n",
       " 0.24365596462793987,\n",
       " 1.067436286840343,\n",
       " 0.877789870198962,\n",
       " -1.1530685749510807,\n",
       " -2.175328012913431,\n",
       " -1.3526451943564521,\n",
       " -1.249413574450389,\n",
       " -0.2799713392252101,\n",
       " -1.1517606118375951,\n",
       " 1.861986542348652,\n",
       " -1.3958150839048868,\n",
       " -0.3782386181834728,\n",
       " -0.7812469115057438,\n",
       " 2.3334190638435968,\n",
       " -2.9422066550580572,\n",
       " 2.007137833298748,\n",
       " -2.563053166150273,\n",
       " -2.6896272601607967,\n",
       " -2.326025146771977,\n",
       " -3.247338295993542,\n",
       " 0.1085956316694244,\n",
       " 0.3112206900268914,\n",
       " -1.0654968537129754,\n",
       " -2.773981286567912,\n",
       " 1.1283103075373402,\n",
       " -3.774778673972213,\n",
       " -0.7914759130636161,\n",
       " 1.024143823730055,\n",
       " -3.0713374609632287,\n",
       " -1.3981864291005577,\n",
       " 2.4799543195318012,\n",
       " -0.9514261733012743,\n",
       " 0.5167379603503042,\n",
       " -0.7906881753151301,\n",
       " -0.9090194467015618,\n",
       " 1.109676878368284,\n",
       " 0.48254954179233395,\n",
       " -1.5583598654156603,\n",
       " -0.7562871913210779,\n",
       " 2.378361477276589,\n",
       " 0.4810684654695234,\n",
       " -1.6355608245475353,\n",
       " -4.1986106502377485,\n",
       " 1.9818547457648816,\n",
       " -3.3652821621528717,\n",
       " 1.0112188950753442,\n",
       " 0.2628379421693451,\n",
       " -1.4838463236241473,\n",
       " -3.4295663946301387,\n",
       " -0.8555087602974275,\n",
       " -0.5275727711581597,\n",
       " -0.009464931219134198,\n",
       " -1.4879276232799286,\n",
       " -0.28379103963030317,\n",
       " -1.5373291865011944,\n",
       " -1.1166256063333608,\n",
       " -2.211556594972003,\n",
       " 1.6228654139589178,\n",
       " -1.2983441808196488,\n",
       " -3.258660703936524,\n",
       " -2.9030519593377506,\n",
       " -0.08382988711836811,\n",
       " -2.3195250493137585,\n",
       " 2.1872879755155585,\n",
       " -2.8046586886948446,\n",
       " -1.7662419383128776,\n",
       " -3.669750223962295,\n",
       " -2.6574792552114426,\n",
       " -0.9130450182690921,\n",
       " -3.4853824540242386,\n",
       " -2.9907529085705438,\n",
       " -0.7038013526674488,\n",
       " -2.590729973352974,\n",
       " -1.0097237510704744,\n",
       " -2.169654346609312,\n",
       " -0.4566831648540507,\n",
       " -4.507487099691993,\n",
       " 0.41817578947247747,\n",
       " 0.44734382132421874,\n",
       " -1.0978855499312332,\n",
       " -1.4715030009943821,\n",
       " -3.115976177103306,\n",
       " -2.8399576070279218,\n",
       " 0.04963528789225114,\n",
       " 0.9822644024742111,\n",
       " 2.3278822329618927,\n",
       " 2.909744616311933,\n",
       " 2.445442738335958,\n",
       " -1.842789758208157,\n",
       " 0.5138205375339038,\n",
       " -1.9462343973480933,\n",
       " -1.7013027999519672,\n",
       " 1.6152630268976793,\n",
       " -3.3963405186938,\n",
       " 0.32073153235207336,\n",
       " -0.7817334988202023,\n",
       " -0.4807960000310839,\n",
       " -1.2590977641199186,\n",
       " 0.2688949563441434,\n",
       " -2.324493574646973,\n",
       " -3.995662280698724,\n",
       " 2.1314517735644127,\n",
       " -1.1905070906424167,\n",
       " 2.316142482806568,\n",
       " 0.30944321386061674,\n",
       " 2.9672692351869037,\n",
       " -0.6006303801126127,\n",
       " -3.6365903342439774,\n",
       " -3.351990658374428,\n",
       " -3.5521066374659127,\n",
       " -2.5258296186347096,\n",
       " -2.1471429962392263,\n",
       " -0.9446027565053903,\n",
       " -0.83887467029447,\n",
       " 0.1925319650180531,\n",
       " 2.5647610103782768,\n",
       " -3.0555492756106633,\n",
       " -1.7328222993913822,\n",
       " -3.4539079887029893,\n",
       " -0.42012528905408075,\n",
       " -3.3929647837914843,\n",
       " 0.4485431998705306,\n",
       " -2.4618345542830586,\n",
       " 0.49756038171940276,\n",
       " -0.5279627564093679,\n",
       " -2.689454218432109,\n",
       " -2.138035927204884,\n",
       " -2.1708027224096442,\n",
       " 2.414549206985576,\n",
       " -1.745787573182692,\n",
       " -0.9273631921209622,\n",
       " 1.2799895664955783,\n",
       " 0.8606579633599308,\n",
       " -2.2530855136607064,\n",
       " -1.3340568388440244,\n",
       " -0.5662486023598746,\n",
       " -0.20953048690830967,\n",
       " -3.118512425489192,\n",
       " -3.8493739403802123,\n",
       " -1.973918292321012,\n",
       " -3.673623554391745,\n",
       " -0.9874138756941357,\n",
       " -3.489122018855782,\n",
       " -1.961535791621208,\n",
       " 1.8139989729799084,\n",
       " 2.6444443521616856,\n",
       " 2.0595730924326694,\n",
       " -0.027196147055181003,\n",
       " 0.4275460140074555,\n",
       " -0.3324827203586526,\n",
       " -0.04036060524429666,\n",
       " -3.654447681078478,\n",
       " -2.8944551000889005,\n",
       " 0.018418881044914823,\n",
       " 0.5798967659692241,\n",
       " -3.45170482360943,\n",
       " -0.5623400779634729,\n",
       " -3.2105706631510578,\n",
       " -3.198739649934589,\n",
       " -1.7205399993958053,\n",
       " 2.9524192467891335,\n",
       " -3.0025709486944074,\n",
       " -0.33540029746984573,\n",
       " 1.9085840867348214,\n",
       " 0.07172593383790825,\n",
       " -0.7951687957887303,\n",
       " -1.6028465752935486,\n",
       " -3.7661163772679274,\n",
       " 1.1575994478242184,\n",
       " 2.8030825295565975,\n",
       " -1.269995038140768,\n",
       " -3.3977082460207506,\n",
       " -3.098481088501657,\n",
       " -3.435674102538544,\n",
       " -0.3174032847069987,\n",
       " -0.4584119085454793,\n",
       " -3.050955878730975,\n",
       " -3.0028121279971662,\n",
       " 0.11271095317511504,\n",
       " -0.8235905737273267,\n",
       " -2.9390774852305817,\n",
       " -1.4704481449746232,\n",
       " 2.142955052256114,\n",
       " -2.2040164874922423,\n",
       " -0.5482451029562592,\n",
       " -1.997769069648573,\n",
       " -0.9789142425973909,\n",
       " -2.991774486577889,\n",
       " -1.0152323560681196,\n",
       " 0.7555228061939367,\n",
       " -0.6266254580351305,\n",
       " -0.9378136340422396,\n",
       " -1.3101087913682583,\n",
       " -2.7164246752017016,\n",
       " 1.5654715470617253,\n",
       " -2.4310494091825228,\n",
       " -4.229328414084136,\n",
       " -2.1681437167798365,\n",
       " 0.491403677976615,\n",
       " 1.2725092188822047,\n",
       " -1.080978019151509,\n",
       " 2.658721581342126,\n",
       " 0.042843462528400045,\n",
       " 1.3289307740484322,\n",
       " -2.45594144144857,\n",
       " -2.693338660666561,\n",
       " -3.1485761791379665,\n",
       " -2.652870122815388,\n",
       " -1.5875375860461727,\n",
       " -3.4952991927775003,\n",
       " -2.0892608411304545,\n",
       " -1.2126052528295406,\n",
       " -0.17399077163017138,\n",
       " -2.909322063434344,\n",
       " 2.67837549536844,\n",
       " 2.4976763525998007,\n",
       " 2.4804801280020525,\n",
       " -0.38938538437937553,\n",
       " -4.576603329664909,\n",
       " -2.115168961388465,\n",
       " 1.6026098631251824,\n",
       " -0.5538660135837777,\n",
       " -3.3445553405857296,\n",
       " -0.10339840182080166,\n",
       " -1.8310207663098719,\n",
       " -0.5612349828044821,\n",
       " 0.5949150641247161,\n",
       " -0.038414300582147766,\n",
       " 0.029685601428111268,\n",
       " -0.9571836082846883,\n",
       " -4.584752709265298,\n",
       " 2.3571335454445297,\n",
       " -0.4136767200408197,\n",
       " -2.1692545557965253,\n",
       " -2.898965963175722,\n",
       " -2.421443995553242,\n",
       " -3.1842690708420984,\n",
       " -2.076292989049874,\n",
       " -0.679459695177149,\n",
       " -1.8197576138654745,\n",
       " 2.059035250398473,\n",
       " -0.45872724319875147,\n",
       " -1.2315365332303336,\n",
       " -0.0572270691735429,\n",
       " 1.6381071456984728,\n",
       " 0.37673559894250686,\n",
       " -1.6249917765289854,\n",
       " -1.7566439270343064,\n",
       " -4.250283505730012,\n",
       " 1.697342618713601,\n",
       " -3.6424947208082266,\n",
       " -0.7631574956731656,\n",
       " -2.3478056416530046,\n",
       " -0.11395642463800668,\n",
       " 0.7876829994293488,\n",
       " -1.3896331451521837,\n",
       " -4.0041357150031,\n",
       " -2.997291500140817,\n",
       " -2.630334960799542,\n",
       " -0.42072379031077467,\n",
       " -2.562963815645521,\n",
       " -1.7528232596264623,\n",
       " 2.25124834669939,\n",
       " -2.7988005130049576,\n",
       " -3.918159813753847,\n",
       " -2.93294205360062,\n",
       " -2.9701021449449145,\n",
       " -0.39347098393960606,\n",
       " -4.635096848178956,\n",
       " -1.4050766298800434,\n",
       " -1.8004776412307646,\n",
       " 1.6075758869195869,\n",
       " ...]"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "lgb_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "sub = pd.read_csv(\"./5-foldCV_avg_sub_36_dummy.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "sub[\"v\"] = output[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "sub[\"v2\"] = sub[\"v\"] - sub[\"predicted\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "sub[sub[\"v2\"] != 0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predicted</th>\n",
       "      <th>v</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, predicted, v, v2]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "119"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}